#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
工作通识知识记忆卡片生成器
生成Anki格式的CSV文件和Markdown格式的卡片
"""

import csv
import json
from typing import List, Dict, Tuple

class WorkGeneralKnowledgeGenerator:
    def __init__(self):
        self.cards = []

    def add_card(self, question: str, answer: str, category: str = "通用"):
        """添加一张卡片"""
        self.cards.append({
            "question": question,
            "answer": answer,
            "category": category
        })

    def format_text_for_anki(self, text: str) -> str:
        """将文本格式化为Anki HTML格式，设置左对齐样式"""
        # 将换行符转换为<br>标签
        html_text = text.replace('\n', '<br>')
        # 用div包裹，设置左对齐样式
        return f'<div style="text-align: left;">{html_text}</div>'

    def generate_project_cards(self):
        """生成项目经历相关的卡片"""

        # 算法移植项目
        self.add_card(
            "在DSP算法移植项目中，为什么使用整数计算代替浮点数计算？",
            "1. 提高运算速度：整数运算比浮点数运算快得多\n   - 原理：整数运算只需要ALU（算术逻辑单元）的简单加法器，而浮点数需要复杂的IEEE 754标准处理（符号位、指数位、尾数位的分离和重组），硬件电路更复杂\n   - 比喻：就像用计算器做整数加减法比做小数运算更快更简单\n\n2. DSP限制：高通DSP不提供浮点数运算支持\n   - 原理：DSP设计时为了降低功耗和面积，只实现了整数运算单元，没有浮点运算单元（FPU）\n   - 比喻：就像一台只有整数计算功能的计算器，不支持小数运算\n\n3. 精度控制：通过合理的缩放因子可以保持足够的精度\n   - 原理：将浮点数乘以固定倍数（如1000）转换为整数，运算后再除以倍数还原，通过选择合适的倍数可以控制精度损失\n   - 比喻：就像用厘米代替米来测量，精度更高但数值更大\n\n4. 功耗优化：整数运算功耗更低\n   - 原理：整数运算电路简单，晶体管翻转次数少，动态功耗低；浮点数运算需要更多逻辑门和时钟周期\n   - 比喻：就像走路比跑步省力，简单的操作消耗更少能量",
            "项目经历-算法移植"
        )

        self.add_card(
            "Ping-Pong Buffer在L2 Cache中的作用是什么？",
            "Ping-Pong Buffer是一种双缓冲技术，在L2 Cache中交替使用两个缓冲区：\n\n原理：\n1. 当一个缓冲区在写入数据时，另一个缓冲区可以读取数据\n   - 原理：通过两个独立的缓冲区实现读写分离，避免单缓冲区的读写冲突（写操作会阻塞读操作）\n   - 比喻：就像餐厅有两个备餐台，一个在准备新菜品时，另一个可以继续上菜，不会互相干扰\n\n2. 避免读写冲突，提高数据吞吐量\n   - 原理：单缓冲区模式下，读写操作需要互斥访问，导致流水线停顿；双缓冲模式下，读写可以并行进行，提高带宽利用率\n   - 比喻：就像双车道比单车道通行效率更高，不会因为对向车辆而阻塞\n\n3. 充分利用L2 Cache的带宽，减少内存访问延迟\n   - 原理：L2 Cache的读写端口可以同时工作，双缓冲让两个端口都能充分利用，减少等待时间；同时数据在Cache中，避免访问更慢的DRAM\n   - 比喻：就像两个工人同时工作，比一个工人效率高一倍\n\n4. 特别适合流水线处理场景\n   - 原理：流水线需要连续的数据流，双缓冲可以保证在处理当前数据块的同时，下一个数据块已经在准备，实现流水线的连续执行\n   - 比喻：就像工厂流水线，一个工位在加工时，下一个工位已经在准备材料，保证流水线不停顿",
            "项目经历-算法移植"
        )

        self.add_card(
            "HVX指令一次可以处理多少个元素？效率提升多少？",
            "HVX（Hexagon Vector eXtensions）一次可以处理128个元素。\n\n原理：\n- HVX是SIMD（单指令多数据）架构，一条指令可以同时对128个数据元素执行相同操作\n- 原理：CPU内部有128个并行的ALU（算术逻辑单元），可以同时处理128个数据，就像128个工人同时做同样的工作\n- 比喻：就像用一台有128个刷子的机器同时刷128块木板，比一把刷子一块一块刷快128倍\n\n效率提升：\n- 理论上可以达到128倍，实际效果取决于算法特性和数据对齐情况\n- 原理：如果数据没有对齐到128字节边界，需要额外的对齐操作；如果算法有数据依赖（前一个结果影响后一个），无法完全并行，实际加速比会降低\n- 比喻：就像128个工人需要协调配合，如果材料摆放不整齐或工作有先后顺序，效率会打折扣\n\n例如：对一个矩阵取绝对值，使用Q6_Vh_abs_Vh()函数可以一次处理128个元素。\n- 原理：取绝对值操作是独立的（每个元素互不影响），非常适合SIMD并行，可以充分利用128个ALU\n- 比喻：就像128个工人同时给128个数字去掉负号，互不干扰，效率最高",
            "项目经历-算法移植"
        )

        self.add_card(
            "L2 Cache预取需要注意哪些问题？",
            "1. 需要提前prefetch，不能等到需要数据时再预取\n   - 原理：预取需要时间（从DRAM到Cache需要几十到几百个时钟周期），如果等到需要时再预取，CPU会等待数据，导致流水线停顿\n   - 比喻：就像提前准备食材，如果等客人点菜再买菜，客人要等很久；提前准备可以让上菜更快\n\n2. 三条以上的fetch指令，如果前面的fetch指令没有执行完会被后面的冲掉\n   - 原理：L2 Cache的预取队列有限（通常只有2-3个槽位），如果预取请求过多，新的请求会覆盖未完成的旧请求，导致预取失效\n   - 比喻：就像只有2-3个采购员，如果同时派太多采购任务，后面的任务会挤掉前面的，导致前面的采购被取消\n\n3. fetch的内容读取比较快，写入有时会很慢，可能有cache miss\n   - 原理：预取是异步操作，读取时如果数据已经在Cache中（命中），速度很快；但写入时需要先获取Cache行的所有权（MESI协议），如果其他核心也在使用，需要等待，导致延迟；如果预取的数据被其他操作替换出Cache，会出现miss\n   - 比喻：就像提前把书放在桌上，读的时候很快，但写笔记时需要先确保没有别人在用这本书，可能等待\n\n4. 通常fetch 8KB以下，多发出几个fetch指令效果会比较好\n   - 原理：8KB大约是L2 Cache行大小的合理倍数，太大可能导致Cache污染（替换掉有用的数据），太小则预取效率低；多个小预取可以更好地利用Cache的并行预取能力\n   - 比喻：就像分批采购，每次买适量（8KB），分多次买，比一次买太多（导致仓库放不下）或太少（效率低）更好",
            "项目经历-算法移植"
        )

        # 功耗大数据项目
        self.add_card(
            "端侧功耗大数据项目中，如何获取原始数据？",
            "使用两种方式获取原始数据：\n\n1. 读节点方式：直接读取系统节点文件（如/sys/class/power_supply/battery/current_now）\n   - 原理：Linux的sysfs文件系统将内核数据暴露为文件，通过文件I/O可以读取硬件状态（如电流、电压），这是最简单直接的方式\n   - 比喻：就像直接看仪表盘读数，简单直接，但只能读取，不能控制\n   - 适用场景：数据已经在sysfs中暴露，且只需要读取的场景\n\n2. Binder方式：通过AIDL接口调用HAL层服务或系统服务（如SurfaceFlinger）\n   - 原理：Binder是Android的IPC机制，通过AIDL定义接口，可以跨进程调用系统服务获取数据；HAL（硬件抽象层）封装了硬件访问，提供统一的接口\n   - 比喻：就像通过电话（Binder）询问专业部门（系统服务），可以获取更复杂的数据或执行操作\n   - 适用场景：需要调用系统服务功能，或数据不在sysfs中的场景（如SurfaceFlinger的屏幕内容）\n\n根据数据源的不同选择合适的获取方式：\n- 原理：读节点方式开销小但功能有限，Binder方式功能强大但需要跨进程通信开销；选择原则是能用节点就用节点，需要复杂功能才用Binder\n- 比喻：就像买东西，能直接买（读节点）就直接买，需要定制服务（Binder）才去专门店",
            "项目经历-功耗大数据"
        )

        self.add_card(
            "Display模块功耗计算为什么采用CWB截屏和白名单结合的方式？",
            "1. CWB（Color Wheel Buffer）截屏可以实时获取屏幕内容，计算精确但开销大\n   - 原理：CWB是图形系统的底层接口，可以获取当前屏幕的像素数据，通过分析像素内容（亮度、颜色分布）可以精确计算显示功耗；但截屏操作需要GPU参与，会触发硬件加速，产生额外功耗\n   - 比喻：就像用高清相机实时拍摄屏幕，能看清每个细节，但相机本身耗电\n\n2. 调用CWB接口会导致电流方波，增加额外功耗\n   - 原理：CWB调用会触发GPU的渲染管线，导致电流突然增加（方波），这个额外的功耗会被计入测量，影响功耗数据的准确性\n   - 比喻：就像测量汽车油耗时，如果测量工具本身也耗油，会干扰测量结果\n\n3. 白名单机制：对于中低端机型，使用白名单代替CWB实时计算\n   - 原理：预先测试不同应用场景的功耗，建立应用-功耗的映射表（白名单），运行时直接查表，避免实时计算的开销\n   - 比喻：就像用查字典代替实时计算，虽然不够精确，但速度快、开销小\n\n4. 牺牲10%左右精度，但可以适配中低端机型，降低功耗开销\n   - 原理：白名单基于历史数据，无法反映实时变化（如视频内容变化），但避免了CWB调用的开销，适合资源受限的中低端机型\n   - 比喻：就像用估算代替精确测量，虽然误差10%，但省时省力，适合资源有限的情况",
            "项目经历-功耗大数据"
        )

        self.add_card(
            "功耗大数据项目从2.0到3.0阶段，架构变化的原因是什么？",
            "主要原因：\n1. 性能优化：native层执行效率更高，内存占用更少\n2. 稳定性：减少APK进程挂掉对业务代码的影响\n3. 业务解耦：APK可以单独发版，native侧跟随整机版本\n4. 安全性：native层代码更难被反编译\n5. 维护成本：去掉臃肿的JNI，配合HIDL转AIDL演进",
            "项目经历-功耗大数据"
        )

        self.add_card(
            "在native层daemon进程中，如何使用SQLite？",
            "1. 使用Android Native层的sqlite3库\n   - 原理：Android NDK提供了sqlite3的C/C++接口，可以直接在native代码中使用，无需通过JNI调用Java层\n   - 比喻：就像直接使用本地工具库，不需要通过翻译\n\n2. 通过自定义的C++隔离接口实现增删改查操作\n   - 原理：封装SQLite操作为C++类，提供统一的接口，隐藏SQL细节，降低使用复杂度，同时便于维护和测试\n   - 比喻：就像用统一的API封装底层数据库操作，使用者不需要懂SQL\n\n3. 建立预警条件：设置SQL trigger策略，当满足条件时自动触发\n   - 原理：SQLite支持触发器（trigger），可以在数据插入/更新时自动执行SQL语句，实现数据驱动的预警机制，无需轮询检查\n   - 比喻：就像设置自动报警器，数据达到阈值时自动报警，不需要人工检查\n\n4. 数据持久化：存储功耗数据、事件数据等\n   - 原理：SQLite是嵌入式数据库，数据存储在本地文件，进程重启后数据不丢失；支持事务，保证数据一致性\n   - 比喻：就像用记事本记录数据，即使断电重启，数据还在\n\n5. 支持复杂查询：按时间、按模块、按事件等维度查询\n   - 原理：SQL支持多条件查询、聚合函数、索引优化，可以高效地按不同维度查询和分析数据\n   - 比喻：就像用Excel的筛选和透视表功能，可以从不同角度分析数据",
            "项目经历-功耗大数据"
        )

        # StatsD项目
        self.add_card(
            "StatsD中Pushed Atom和Pulled Atom的区别是什么？",
            "1. Pushed Atom（主动型）：\n   - 由应用主动上报事件\n     * 原理：应用在事件发生时立即上报，数据流是推式的（push），实时性好\n     * 比喻：就像快递员主动送货上门，有货就送\n   - 底层实现为Unix domain socket通信（本地IPC）\n     * 原理：Unix domain socket是同一主机内的高性能IPC机制，适合本地进程间通信，开销较小；客户端通过libstatssocket库写入事件到StatsD的socket，StatsD通过StatsSocketListener接收事件\n     * 比喻：就像内部对讲机（Unix domain socket），本地通信效率高，不需要网络开销\n   - 使用库函数上报\n     * 原理：提供简单的API，应用调用即可，使用方便\n   - 适合事件驱动的数据采集\n     * 原理：事件发生时间不确定，推式模式可以及时上报，不会丢失\n     * 比喻：就像突发事件，需要立即报告，不能等定期检查\n\n2. Pulled Atom（被动型）：\n   - 由StatsD主动拉取数据\n     * 原理：StatsD按固定周期主动查询数据，数据流是拉式的（pull），可以批量获取\n     * 比喻：就像定期去仓库取货，按计划执行\n   - 底层实现为binder通信\n     * 原理：Binder是Android本地IPC，效率高、安全性好，适合系统内通信\n     * 比喻：就像内部对讲机（binder），本地通信效率高\n   - 使用注册回调添加\n     * 原理：应用注册回调函数，StatsD调用回调获取数据，解耦数据提供者和消费者\n   - 适合定时采样的数据采集\n     * 原理：数据变化缓慢或需要定期采样，拉式模式可以统一管理采样频率\n     * 比喻：就像定期体检，按计划检查身体状况",
            "项目经历-StatsD"
        )

        self.add_card(
            "StatsD中灵活结算温度区间数据的核心思路是什么？",
            "核心思路：为每一段温度区间打上两个标签\n\n1. 温度区间的编号：标识当前温度等级\n   - 原理：将连续的温度值离散化为区间（如0-30°C为区间1，30-50°C为区间2），用编号标识，简化数据处理\n   - 比喻：就像把温度分成几个等级（冷、温、热），用数字编号\n\n2. 温度区间的开始时间戳：标识这段温度区间的起始时间\n   - 原理：记录温度区间切换的时间点，可以计算每个区间持续的时间，用于后续分析\n   - 比喻：就像记录每次换挡的时间，可以分析每个档位用了多久\n\n核心机制：\n- 原理：StatsD原本是按固定时间窗口（如每小时）结算数据，但温度变化不规律，需要按温度变化点结算。通过在数据上打标签，可以在固定时间窗口内识别温度区间变化，实现灵活结算\n- 比喻：就像原本按小时统计，但需要按温度变化统计，通过给数据贴标签（区间编号+时间戳），可以在固定统计周期内识别温度变化点\n\n效果：\n- 获取随温度变化的数据，并得到每段温度区间变化的开始时间和结束时间\n- 原理：通过标签可以识别温度区间切换点，计算每个区间的持续时间和数据，实现按温度区间的灵活结算\n- 比喻：就像在时间轴上标记温度变化点，可以分析每个温度区间的特征",
            "项目经历-StatsD"
        )

        self.add_card(
            "StatsD中Metric分为哪两类？各有什么特点？",
            "第一类：结构固定的Metric（Count、Duration、Value）\n- 数据都是整数或浮点数\n  * 原理：这些Metric只包含数值，数据结构简单，可以用基本类型表示\n  * 比喻：就像只记录数字，格式统一\n- 解析简单，结构固定\n  * 原理：不需要解析复杂结构，直接读取数值即可，解析器代码简单\n  * 比喻：就像读取Excel中的数字列，格式固定，容易处理\n\n第二类：结构灵活的Metric（Gauge、Event）\n- 结构随Atom的结构而变化\n  * 原理：Gauge和Event可以包含任意字段，结构由Atom定义决定，不同Atom可能有不同的字段\n  * 比喻：就像不同表格有不同的列，结构不固定\n- 解析复杂，需要proto文件\n  * 原理：需要根据proto定义解析字段，支持嵌套结构、数组等复杂类型，解析器需要动态处理\n  * 比喻：就像需要根据表格模板（proto）来解析数据，不同模板解析方式不同\n- 实际应用中只将用到的一部分proto抄写并编译进来\n  * 原理：完整proto文件很大，只编译需要的部分可以减少代码体积和编译时间，同时避免依赖问题\n  * 比喻：就像只带需要的工具，而不是整个工具箱",
            "项目经历-StatsD"
        )

        self.add_card(
            "Pulled Atom在累计数据流中采样时需要注意什么？",
            "1. 如果使用方只有一个：可以在采样后立刻重置数据，配置文件编写相对容易\n   - 原理：单用户场景下，采样后重置不会影响其他用户，可以简化逻辑，直接读取当前值然后清零\n   - 比喻：就像只有一个读者，看完书可以立即归还，不影响其他人\n\n2. 如果有多方使用数据：只能让数据始终累加，需要设计数据循环或定期清零的机制\n   - 原理：多用户场景下，如果一方重置会影响其他方，所以不能重置；累计数据会不断增长，需要防止溢出，可以通过循环计数（如uint32溢出后从0开始）或定期清零\n   - 比喻：就像多个读者共用一本书，不能随意修改，需要设计循环使用机制\n\n3. 在配置文件中写明只统计增量\n   - 原理：累计数据是绝对值，需要计算两次采样的差值（增量）才能得到变化量；在配置中明确说明，避免误用累计值\n   - 比喻：就像记录总里程和本次里程，需要说明统计的是增量\n\n4. 针对重置的情况添加过滤规则\n   - 原理：如果数据被重置（从大值突然变小），差值计算会出现负数或异常大值，需要过滤这些异常数据\n   - 比喻：就像里程表归零后，差值计算会异常，需要识别并过滤",
            "项目经历-StatsD"
        )

        # 日志动态开关项目
        self.add_card(
            "日志动态开关下发项目中，为什么使用ContentProvider？",
            "原因：\n\n1. OPush后台不稳定，第一次注册可能在开机不久后失败\n   - 原理：OPush服务在系统启动时可能还未完全初始化，此时注册可能失败；ContentProvider可以作为数据共享的中间层，解耦注册逻辑\n   - 比喻：就像邮局还没开门，直接寄信会失败，但可以先放在邮箱（ContentProvider）里\n\n2. 非常驻进程启动后，通过ContentProvider向常驻进程query\n   - 原理：ContentProvider是Android的跨进程数据共享机制，非常驻进程可以通过ContentProvider查询常驻进程的数据，无需直接通信\n   - 比喻：就像通过共享数据库查询，不需要直接联系对方\n\n3. 如果已有regID，直接返回；如果没有，触发重新注册\n   - 原理：ContentProvider可以缓存regID，非常驻进程查询时如果已有就直接返回，避免重复注册；如果没有，触发常驻进程重新注册\n   - 比喻：就像查字典，有就直接返回，没有就重新查找\n\n4. 提高注册成功率，确保推送顺利进行\n   - 原理：通过ContentProvider解耦，非常驻进程不需要关心注册细节，只需要查询；常驻进程负责注册和缓存，提高可靠性\n   - 比喻：就像分工明确，查询者只负责查，注册者负责注册，各司其职，提高成功率",
            "项目经历-日志开关"
        )

        self.add_card(
            "DAO模式在日志开关项目中的作用是什么？",
            "1. 实现业务逻辑和数据访问逻辑的隔离\n   - 原理：DAO（Data Access Object）模式将数据访问代码封装在DAO类中，业务层只调用DAO接口，不关心底层实现（SQLite、文件等），降低耦合度\n   - 比喻：就像业务层是顾客，DAO是服务员，顾客点菜不需要知道厨房怎么做菜\n\n2. 提供统一的数据访问接口\n   - 原理：所有数据操作都通过DAO接口，接口统一，即使底层存储方式改变（如从SQLite改为Room），业务层代码不需要修改\n   - 比喻：就像统一的ATM接口，无论背后是哪个银行，使用方式都一样\n\n3. 便于测试和维护\n   - 原理：可以mock DAO接口进行单元测试，不需要真实的数据库；数据访问逻辑集中，修改时只需要改DAO层\n   - 比喻：就像测试时可以模拟数据源，不需要真实环境\n\n4. 支持复杂查询：查询结果以List返回，按时间降序，并清理多余条目\n   - 原理：DAO封装SQL查询逻辑，可以执行复杂查询（排序、过滤、分页），返回统一的数据结构（List），业务层直接使用\n   - 比喻：就像服务员不仅上菜，还负责摆盘和清理，顾客直接享用\n\n5. 使用BigDecimal代替Long.parseLong解析时间戳字符串，避免精度问题\n   - 原理：时间戳可能是高精度（纳秒级），Long可能溢出；BigDecimal可以处理任意精度的数字，避免精度丢失和溢出问题\n   - 比喻：就像用高精度天平代替普通秤，可以测量更精确的重量",
            "项目经历-日志开关"
        )

        self.add_card(
            "在DSP算法移植中，如何处理高通DSP不支持除法和浮点数运算的限制？",
            "1. 除法运算：使用乘法+位运算代替\n   - 例如：a/b 可以转换为 a * (1/b)，其中1/b可以预先计算\n     * 原理：除法可以转换为乘法（a/b = a * (1/b)），1/b是常数可以预先计算，乘法比除法快得多\n     * 比喻：就像用乘法表代替除法，预先算好倒数，直接查表\n   - 使用位移代替除以2的幂次\n     * 原理：除以2的n次方等价于右移n位（a/8 = a >> 3），位移是硬件级操作，速度极快\n     * 比喻：就像用移位代替除法，就像二进制中除以2就是右移一位\n   - 注意溢出和精度问题\n     * 原理：乘法可能溢出，需要检查；1/b的精度有限，可能引入误差，需要合理选择精度\n     * 比喻：就像用近似值代替精确值，需要注意误差\n\n2. 浮点数运算：使用整数计算代替\n   - 将浮点数乘以缩放因子转换为整数\n     * 原理：浮点数乘以固定倍数（如1000）得到整数，保留小数信息\n     * 比喻：就像用分代替元，1.5元变成150分\n   - 进行整数运算\n     * 原理：整数运算速度快，硬件支持好\n   - 最后除以缩放因子得到结果\n     * 原理：运算结果除以缩放因子还原为浮点数\n     * 比喻：就像算完后再转换回元\n\n3. 精度控制：通过合理的缩放因子保持足够的精度\n   - 原理：缩放因子越大精度越高，但可能溢出；需要权衡精度和范围\n   - 比喻：就像用更小的单位（毫米vs厘米）测量，精度更高但数值更大\n\n4. 性能优化：整数运算比浮点数运算快得多\n   - 原理：整数运算电路简单，浮点数需要处理符号、指数、尾数，电路复杂，速度慢",
            "项目经历-算法移植"
        )

        self.add_card(
            "端侧功耗大数据项目中，如何保证功耗计算的误差在可接受范围内？",
            "1. 数据校准：与功耗板的测量结果对比，进行校准\n   - 原理：功耗板是硬件测量设备，精度高，作为标准参考；软件计算结果与功耗板对比，计算校准系数（如线性校正、非线性校正），修正软件误差\n   - 比喻：就像用标准砝码校准天平，确保测量准确\n\n2. 误差控制：确保软件计算误差在10%以内\n   - 原理：10%是工程上可接受的误差范围，通过校准和优化算法，将误差控制在阈值内\n   - 比喻：就像允许测量有10%的误差，在这个范围内认为合格\n\n3. 白名单机制：对于中低端机型，使用白名单代替实时计算，牺牲10%精度以降低功耗\n   - 原理：中低端机型资源有限，实时计算功耗高；白名单基于历史数据，查表即可，功耗低但精度略差（约10%），在可接受范围内\n   - 比喻：就像用估算代替精确计算，虽然误差10%，但省电省资源\n\n4. 验证实验：设计验证实验，对比不同场景下的误差\n   - 原理：在不同场景（游戏、视频、待机等）下测试，收集误差数据，分析误差分布和原因，针对性优化\n   - 比喻：就像在不同条件下测试，找出误差规律\n\n5. 持续优化：根据实际数据不断优化计算模型\n   - 原理：收集真实场景数据，分析误差模式，调整计算模型参数，迭代优化\n   - 比喻：就像根据实际使用情况不断调整算法，越用越准\n\n6. 测试流程：规定新的测试、适配流程，确保误差达标\n   - 原理：建立标准化的测试流程，每个新机型/新版本都要经过误差测试，确保达标后才能发布\n   - 比喻：就像建立质量检查流程，确保每个产品都合格",
            "项目经历-功耗大数据"
        )

        self.add_card(
            "功耗大数据项目中，为什么需要功耗模型自己计算各个子系统的功耗，而不是直接从PMIC拿？",
            "功耗大数据项目需要自己建立功耗模型计算各个子系统的功耗，而不是直接从PMIC获取，主要有以下几个原因：\n\n1. PMIC数据的局限性：\n   - PMIC只能提供整体电流/电压数据，无法细分到各个子系统\n   - 原理：PMIC测量的是供电轨的总电流，无法区分是CPU、GPU、Display、Modem等哪个子系统消耗的；就像只能看到总电表，看不到每个电器的用电量\n   - 比喻：就像只能看到整栋楼的总用电量，看不到每个房间的用电量\n   - 实际需求：需要知道CPU、GPU、Display、Modem、Camera等各个子系统的功耗，才能定位问题\n\n2. 需要更详细的信息来定位问题：\n   - 问题定位需要知道：哪个模块、哪个应用、哪个场景、哪个时间段的功耗\n   - 原理：PMIC只提供电流电压，无法提供业务维度的信息（如应用名称、场景类型、模块状态等），无法满足问题定位的需求\n   - 比喻：就像只知道总用电量，不知道是哪个电器、什么时候用的，无法定位问题\n   - 功耗模型可以结合：\n     * 系统状态信息（CPU频率、GPU频率、屏幕亮度等）\n     * 应用信息（前台应用、后台应用）\n     * 场景信息（游戏、视频、待机等）\n     * 时间信息（时间段、持续时间）\n   - 原理：功耗模型可以结合多种数据源，提供多维度的功耗分析，满足问题定位需求\n   - 比喻：就像综合多种信息，提供详细的用电分析报告\n\n3. 适配成本考虑：\n   - 不同机型使用不同的PMIC，接口和寄存器可能不同\n   - 原理：不同厂商（如高通、MTK）的PMIC接口不同，不同机型的PMIC型号可能不同，直接读取PMIC需要为每个机型适配，适配成本高\n   - 比喻：就像不同品牌的电表接口不同，需要为每个品牌单独适配\n   - 功耗模型可以统一接口：\n     * 通过sysfs节点统一接口（如/sys/class/power_supply/battery/current_now）\n     * 通过系统服务统一接口（如BatteryManager）\n     * 适配成本低，一套代码可以适配多个机型\n   - 原理：功耗模型使用操作系统提供的统一接口，不直接依赖PMIC硬件，适配成本低\n   - 比喻：就像使用统一的电表接口，不需要为每个品牌单独适配\n\n4. PMIC可能没有某些数据：\n   - PMIC主要测量供电轨的电流，但某些功耗无法直接测量\n   - 例如：\n     * Display功耗需要结合屏幕内容（亮度、颜色分布）计算，PMIC无法提供这些信息\n     * CPU/GPU功耗需要结合频率、负载等信息计算，PMIC只能提供供电电流\n     * 某些模块可能由其他电源芯片供电，PMIC无法监测\n   - 原理：PMIC只能测量它供电的模块的电流，无法提供计算功耗所需的所有信息\n   - 比喻：就像电表只能测量用电量，无法知道电器的使用状态和效率\n\n5. 需要结合业务逻辑和场景信息：\n   - 功耗计算需要结合业务逻辑：\n     * 不同应用场景的功耗特征不同（游戏、视频、待机等）\n     * 不同应用的使用模式不同（前台、后台、唤醒频率等）\n     * 不同模块的功耗模型不同（CPU、GPU、Display等）\n   - 原理：功耗模型可以结合业务逻辑和场景信息，提供更准确的功耗计算和问题定位\n   - 比喻：就像结合使用场景和电器状态，提供更准确的用电分析",
            "项目经历-功耗大数据"
        )

        self.add_card(
            "StatsD项目中，如何处理非固定格式的埋点结算？",
            "1. 增加埋点field：在Atom中添加额外的字段\n   - 原理：Atom是StatsD的数据单元，可以包含多个字段；非固定格式需要在Atom中增加自定义字段，用于存储灵活的数据\n   - 比喻：就像在表格中增加新列，存储额外信息\n\n2. 结合已有Metric机制：利用StatsD的Metric解析机制\n   - 原理：StatsD的Metric机制已经支持解析Atom数据，可以复用现有框架，只需要扩展解析逻辑\n   - 比喻：就像在现有框架上扩展功能，不需要重写\n\n3. 灵活解析：支持固定格式和非固定格式的Metric\n   - 原理：解析器需要判断Metric类型，固定格式直接读取数值，非固定格式根据proto定义解析字段\n   - 比喻：就像识别不同格式的文件，用不同方式解析\n\n4. 分类处理：\n   - 固定格式（Count、Duration、Value）：数据是整数或浮点数\n     * 原理：这些Metric结构固定，解析简单，性能好\n     * 比喻：就像固定格式的表格，直接读取\n   - 非固定格式（Gauge、Event）：结构随Atom结构变化\n     * 原理：需要根据proto定义动态解析，支持嵌套、数组等复杂结构\n     * 比喻：就像动态格式的表格，需要根据模板解析\n\n5. Proto文件：只将用到的一部分proto抄写并编译进来，解决protobuf解码问题\n   - 原理：完整proto文件很大，只编译需要的部分可以减少代码体积；protobuf需要proto定义才能解码，抄写部分定义可以避免依赖完整proto\n   - 比喻：就像只带需要的工具，而不是整个工具箱",
            "项目经历-StatsD"
        )

        self.add_card(
            "StatsD的核心功能是什么？",
            "StatsD是Android系统级的统计服务，主要用来收集、聚合和上报各种系统或应用的指标数据。它允许其他模块注册自己的统计需求，比如指定要收集哪些数据、用什么方式聚合（比如计数、求和、平均值），然后StatsD会按照注册时的规则去采集和处理数据。\n\n- 原理：StatsD是AOSP中的原生服务（native service），位于frameworks/base/cmds/statsd/，作为守护进程运行，独立于Android框架，可以监控系统事件\n- 比喻：就像系统级的统计中心，各个模块可以向它注册统计需求，它会按照规则收集和处理数据",
            "项目经历-StatsD"
        )

        self.add_card(
            "APP层和Native层注册StatsD的通信方式有什么区别？",
            "APP层和Native层都能注册StatsD，不过通信方式确实不太一样：\n\nAPP层：\n1. 一般会通过Android提供的Java API，比如用StatsManager类来注册\n   - 原理：StatsManager位于android.app包，通过StatsCompanionService与StatsService通信；StatsCompanionService运行在system_server进程中，通过Binder与native StatsService通信\n   - 比喻：就像通过Java接口调用，底层通过Binder通信\n2. 底层其实是通过Binder机制和StatsD服务通信的，因为Binder是Android跨进程通信的主要方式\n   - 原理：Binder是Android本地IPC，效率高、安全性好，适合系统内通信\n   - 比喻：就像内部对讲机（Binder），本地通信效率高\n3. APP作为客户端，通过Binder调用StatsD的注册接口，传递统计规则和Atom类型\n\nNative层：\n1. 通常会用NDK里的libstatslog库，直接调用C/C++接口\n   - 原理：libstatslog库提供native接口，可以直接在C/C++代码中使用\n   - 比喻：就像直接使用本地工具库，不需要通过翻译\n2. 通信方式取决于操作类型：\n   - Pushed Atom（logEvent/write）：使用Unix domain socket，不是Binder\n     * 原理：根据AOSP源码，libstatslog的write和logEvent函数通过Unix domain socket发送数据到statsd，不是Binder\n     * 比喻：就像使用Unix domain socket（内部对讲机）直接通信，不需要Binder\n   - Pulled Atom（注册回调）：使用Binder，与APP层相同\n     * 原理：Pulled Atom通过Binder注册回调，StatsD通过Binder调用回调获取数据\n     * 比喻：就像通过Binder注册回调，与APP层相同\n\nPushed Atom和Pulled Atom的通信方式：\n- Pushed Atom：使用Unix domain socket进行本地IPC，不管是APP层还是Native层，都是通过Unix domain socket写入事件\n  * 原理：Unix domain socket是同一主机内的高性能IPC机制，适合本地进程间通信，开销较小；客户端通过libstatssocket库写入事件到StatsD的socket，StatsD通过StatsSocketListener接收事件\n  * 比喻：就像内部对讲机（Unix domain socket），本地通信效率高，不需要网络开销\n- Pulled Atom：使用Binder注册回调，StatsD会根据注册时的规则，定期通过Binder调用回调获取数据\n  * 原理：Pulled Atom需要回调机制，StatsD调用注册的回调函数获取数据，需要双向通信，Binder更适合\n  * 比喻：就像需要双向电话，可以互相调用",
            "项目经历-StatsD"
        )

        self.add_card(
            "StatsD中什么时候使用Socket通信？",
            "StatsD的通信机制：\n\n本地通信：\n- Pushed Atom：使用Unix domain socket（本地IPC），不是网络socket\n  * 原理：根据AOSP源码，StatsD使用StatsSocketListener监听Unix domain socket接收log事件；Unix domain socket是同一主机内的高性能IPC机制，不涉及网络通信\n  * 比喻：就像内部对讲机（Unix domain socket），本地通信效率高，不需要网络开销\n- Pulled Atom：使用Binder IPC\n  * 原理：Pulled Atom通过Binder注册回调，StatsD通过Binder调用回调获取数据\n  * 比喻：就像通过Binder（内部电话）通信\n- 服务注册和配置：使用Binder IPC\n  * 原理：StatsManager通过StatsCompanionService与StatsService通信，使用Binder IPC\n  * 比喻：就像通过Binder注册和配置\n\n远程上报：\n- StatsD本身不直接负责远程上报\n  * 原理：根据AOSP架构，StatsD主要负责收集、聚合和生成ConfigMetricsReport，报告存储在设备本地\n  * 比喻：就像统计中心只负责收集和整理数据，不负责上传\n- StatsD主要负责收集、聚合和生成ConfigMetricsReport，报告存储在设备本地\n  * 原理：StatsD收集数据并生成报告，报告存储在本地，可以被系统组件或应用访问\n  * 比喻：就像生成统计报告，存储在本地\n- 远程上报通常由应用层或系统服务（如StatsCompanionService）负责，可能使用网络socket\n  * 原理：上传过程的具体实现（网络协议、端点等）取决于使用StatsD框架的系统或应用的实现细节\n  * 比喻：就像其他服务负责上传报告到远程服务器\n- 上传过程的具体实现（网络协议、端点等）取决于使用StatsD框架的系统或应用的实现细节\n\n总结：StatsD使用Unix domain socket进行本地IPC（Pushed Atom），使用Binder进行服务通信（Pulled Atom、配置等）。远程上报不是StatsD的直接职责，而是由其他服务或应用负责。",
            "项目经历-StatsD"
        )

        self.add_card(
            "为什么StatsD中Push Atom上报方使用Socket而不是Binder？",
            "StatsD中Push Atom（主动上报）使用Unix domain socket而不是Binder，这是基于AOSP源码设计和系统架构的合理选择，主要原因包括：\n\n1. 早期启动阶段可用性：\n   - Binder服务启动时机：\n     * Binder驱动和ServiceManager在系统启动的较晚阶段才完全初始化\n     * Binder服务需要等待系统框架完全启动后才能正常使用\n     * 原理：Binder依赖Android框架层，系统启动早期（如init阶段）Binder服务可能不可用\n     * 比喻：就像电话系统需要等电话局完全启动后才能使用\n   - Unix domain socket在init阶段可用：\n     * 根据AOSP源码（frameworks/base/cmds/statsd/src/StatsService.cpp和init.rc配置），StatsD的socket在init阶段通过init进程创建\n     * init.rc配置示例：`socket statsd stream 0660 root system`\n     * 创建路径：`/dev/socket/statsd`，由init进程在启动StatsD服务时创建并传递文件描述符\n     * 原理：Unix domain socket是内核级IPC机制，不依赖应用框架，可以在init阶段创建\n     * 比喻：就像对讲机系统，系统启动就可以使用，不需要等电话局\n   - StatsD需要早期启动：\n     * StatsD是native守护进程，需要在系统启动早期就开始收集统计信息\n     * 系统启动过程中就有大量事件需要上报（如进程启动、系统状态变化等）\n     * 原理：StatsD需要从系统启动早期就开始工作，此时Binder可能不可用\n     * 比喻：就像需要在工厂启动初期就开始统计，此时电话系统还没好，只能用对讲机\n\n2. 简单性和性能优势：\n   - Unix domain socket实现简单：\n     * 根据AOSP源码（frameworks/base/cmds/statsd/src/StatsSocketListener.cpp），StatsSocketListener直接监听socket文件描述符，接收数据\n     * 使用简单的read/write系统调用，不需要复杂的序列化/反序列化\n     * 原理：Unix domain socket是低级的IPC机制，实现简单直接，适合native守护进程\n     * 比喻：就像直接读写文件，简单直接，不需要复杂的协议\n   - 低延迟：\n     * Unix domain socket是本地IPC，数据在内核空间直接传递，延迟极低（微秒级）\n     * 没有Binder的序列化、权限检查、驱动转发等开销\n     * 原理：Unix domain socket在内核空间完成数据传输，开销最小\n     * 比喻：就像直接传递文件，不需要中转站，速度快\n   - 适合高频上报：\n     * Push Atom是事件驱动的，可能频繁触发（如每次点击、每次网络请求）\n     * 性能敏感：延迟必须足够低，不能影响应用性能\n     * 原理：高频上报需要低延迟和低开销，Unix domain socket更适合\n     * 比喻：就像频繁传递小文件，需要快速通道，不需要复杂的快递系统\n\n3. 安全性和访问控制：\n   - 文件系统权限控制：\n     * 根据AOSP源码的init.rc配置，StatsD socket权限为0660（`rw-rw----`）\n     * 用户组为system，只有system用户组的进程可以访问\n     * 原理：Unix domain socket作为文件系统节点，可以使用标准的文件权限控制访问\n     * 比喻：就像文件访问权限，只有有权限的用户才能访问\n   - SELinux安全上下文：\n     * 可以设置SELinux安全标签，进一步限制访问\n     * 只有符合SELinux策略的进程才能连接socket\n     * 原理：结合文件权限和SELinux策略，提供多层安全保护\n     * 比喻：就像多重安全检查，确保只有授权的进程才能访问\n   - 进程隔离：\n     * 只有特定UID/GID的进程可以连接socket\n     * 防止未授权进程上报数据或干扰StatsD\n     * 原理：通过文件权限实现进程级别的访问控制\n     * 比喻：就像只有内部员工才能使用内部通道\n\n4. 通信模式匹配：\n   - Push Atom的特点：\n     * 单向通信：应用上报数据给StatsD，不需要返回值\n     * 事件驱动：事件发生时立即上报，不需要轮询\n     * 简单数据传递：主要是序列化的Atom数据，不需要复杂的对象引用\n     * 原理：Push Atom是简单的单向数据上报，不需要Binder的复杂特性\n     * 比喻：就像发邮件，只需要发送数据，不需要复杂的交互\n   - Unix domain socket的优势：\n     * 支持流式通信（SOCK_STREAM），适合连续的事件流\n     * 数据按序到达，保证事件顺序\n     * 原理：流式socket适合事件流式上报，保证顺序和可靠性\n     * 比喻：就像流水线，数据按顺序传递\n   - Binder的复杂性：\n     * Binder设计用于复杂的RPC调用，支持对象引用、回调、事务等\n     * 对于简单的数据上报，Binder的复杂性是多余的\n     * 原理：Binder的复杂特性对Push Atom来说是过度设计\n     * 比喻：就像用复杂的快递系统传递简单文件，没有必要\n\n5. AOSP源码实现细节：\n   - StatsSocketListener实现：\n     * 源码位置：`frameworks/base/cmds/statsd/src/StatsSocketListener.cpp`\n     * StatsSocketListener继承自SocketListener，监听socket文件描述符\n     * 使用epoll或select机制监听socket事件，有数据时调用onDataAvailable处理\n     * 原理：使用高效的I/O多路复用机制，处理多个客户端连接\n     * 比喻：就像高效的服务台，可以同时处理多个客户\n   - 客户端库实现：\n     * 源码位置：`frameworks/base/libs/libstatssocket/`\n     * libstatssocket库提供简单的API（如stats_log_write）供应用调用\n     * 内部实现：打开`/dev/socket/statsd`，写入序列化的Atom数据\n     * 原理：提供简单易用的API，隐藏socket通信细节\n     * 比喻：就像提供简单的接口，内部处理复杂的通信\n   - init.rc配置：\n     * 源码位置：`frameworks/base/cmds/statsd/etc/init.statsd.rc`或类似位置\n     * 配置示例：`socket statsd stream 0660 root system`\n     * init进程创建socket，传递文件描述符给StatsD进程\n     * 原理：init进程统一管理系统服务，创建和管理socket\n     * 比喻：就像系统管理员统一创建和管理通信通道\n\n6. 与Pulled Atom的对比：\n   - Pulled Atom使用Binder：\n     * Pulled Atom需要回调机制：StatsD调用注册的回调函数获取数据\n     * 需要双向通信：StatsD发起调用，回调返回数据\n     * 需要对象引用：回调是对象引用，需要Binder的对象引用机制\n     * 原理：Pulled Atom需要复杂的RPC机制，Binder更适合\n     * 比喻：就像需要双向电话，可以互相调用\n   - Push Atom使用Socket：\n     * Push Atom只需要单向数据传递：应用发送数据，StatsD接收\n     * 不需要回调：事件发生直接上报，不需要等待调用\n     * 不需要对象引用：只是数据传递，不是对象交互\n     * 原理：Push Atom是简单的单向数据流，Socket更合适\n     * 比喻：就像单向邮件，只需要发送，不需要回复\n   - 设计一致性：\n     * 不同的通信需求使用不同的IPC机制，这是合理的设计\n     * 原理：根据通信模式选择合适的IPC机制，优化性能和复杂度\n     * 比喻：就像根据任务选择工具，简单任务用简单工具，复杂任务用复杂工具\n\n7. 性能数据对比（基于AOSP设计和实际测试）：\n   - Unix domain socket：\n     * 延迟：微秒级（通常<10μs）\n     * 吞吐量：高（可以处理大量小消息）\n     * CPU开销：低（主要是系统调用开销）\n     * 原理：内核空间直接传输，开销最小\n     * 比喻：就像直接传递，速度快，开销小\n   - Binder：\n     * 延迟：毫秒级（通常>1ms，包含序列化、驱动转发等）\n     * 吞吐量：中等（受序列化和驱动限制）\n     * CPU开销：较高（序列化、权限检查、驱动处理）\n     * 原理：多层处理和检查，开销较大\n     * 比喻：就像多层中转，速度慢，开销大\n   - 对Push Atom的影响：\n     * Push Atom可能高频触发（如每秒数千次事件）\n     * 使用Unix domain socket可以显著降低延迟和CPU开销\n     * 原理：高频上报需要低延迟和低开销，Unix domain socket的优势明显\n     * 比喻：就像高频传递需要快速通道，Unix domain socket是最佳选择\n\n8. 总结：\n   - 核心原因：\n     * 早期启动可用性：Unix domain socket在init阶段即可使用，Binder需要等待框架启动\n     * 简单性和性能：Unix domain socket实现简单，延迟低，适合高频上报\n     * 安全性：Unix domain socket通过文件权限和SELinux提供访问控制\n     * 通信模式匹配：Push Atom是单向事件流，不需要Binder的复杂特性\n     * 原理：根据AOSP源码设计和实际需求，Unix domain socket是Push Atom的最佳选择\n   - 设计哲学：\n     * 不同的通信需求使用不同的IPC机制\n     * Push Atom（单向事件流）→ Unix domain socket\n     * Pulled Atom（双向RPC调用）→ Binder\n     * 原理：选择合适的工具解决特定的问题，避免过度设计\n     * 比喻：就像根据任务选择工具，简单任务用简单工具\n   - 实际效果：\n     * StatsD可以在系统启动早期就开始工作\n     * Push Atom上报延迟低，不影响应用性能\n     * 系统资源占用低，适合移动设备的资源限制\n     * 原理：Unix domain socket的设计选择优化了系统性能和资源使用\n   - 原理：结合AOSP源码设计和系统架构，StatsD中Push Atom使用Unix domain socket而不是Binder，是因为Unix domain socket在早期启动可用性、简单性、性能、安全性和通信模式匹配等方面更适合Push Atom的需求，而Binder的复杂特性对简单的单向数据上报来说是过度设计\n   - 比喻：就像工厂需要从启动初期就开始统计，此时电话系统（Binder）还没好，只能用对讲机（Unix domain socket）；而且统计是单向的、高频的，对讲机（Unix domain socket）更简单、更快、更适合",
            "项目经历-StatsD"
        )

        self.add_card(
            "在native层daemon进程中，如何使用map保存binder对象实现一对多通信？",
            "1. 使用map保存binder对象：使用shared_ptr管理binder对象生命周期\n   - 原理：map的key是客户端标识，value是binder对象的智能指针；shared_ptr自动管理内存，当最后一个引用释放时自动删除对象，避免内存泄漏\n   - 比喻：就像用通讯录（map）保存联系人（binder对象），智能指针确保联系人信息自动清理\n\n2. 一对多注册：一个服务可以注册多个客户端\n   - 原理：服务端维护一个map，每个客户端注册时在map中添加一个条目，实现一个服务对应多个客户端\n   - 比喻：就像一个广播站可以有很多听众，每个听众注册后都能收到广播\n\n3. 通信机制：\n   - 服务端维护一个map，key可以是客户端标识，value是binder对象\n     * 原理：map提供O(log n)的查找效率，可以根据客户端标识快速找到对应的binder对象\n     * 比喻：就像用字典查单词，根据key快速找到value\n   - 客户端通过binder接口注册\n     * 原理：客户端调用服务的注册接口，将自己的binder对象传递给服务端，服务端保存到map中\n     * 比喻：就像听众向广播站登记，留下联系方式\n   - 服务端可以向所有注册的客户端发送数据\n     * 原理：遍历map中的所有binder对象，调用每个对象的接口发送数据，实现广播\n     * 比喻：就像广播站向所有登记的听众发送消息\n\n4. DeathRecipient：注册DeathRecipient，当客户端进程死亡时自动清理\n   - 原理：DeathRecipient是Binder的死亡通知机制，当客户端进程死亡时，Binder驱动会通知服务端，服务端可以自动从map中删除对应的binder对象\n   - 比喻：就像自动检测听众离线，从通讯录中删除\n\n5. 线程安全：使用锁保护map的并发访问\n   - 原理：多个线程可能同时访问map（注册、删除、遍历），需要使用互斥锁保护，避免数据竞争\n   - 比喻：就像多人同时修改通讯录，需要排队，一次只能一个人操作",
            "项目经历-功耗大数据"
        )

        self.add_card(
            "性能看板项目中，如何解析Trace文件并入库？",
            "1. Trace文件格式：解析perfetto trace文件（protobuf格式）\n   - 原理：Perfetto是Android的性能追踪工具，trace文件使用protobuf序列化，需要根据proto定义反序列化解析\n   - 比喻：就像解析压缩文件，需要知道格式才能正确解压\n\n2. 数据提取：提取性能相关数据（CPU调度、内存分配、I/O操作等）\n   - 原理：Trace文件包含大量数据，需要过滤出关键性能指标（如CPU使用率、内存分配、I/O延迟），提取为结构化数据\n   - 比喻：就像从日志中提取关键信息，过滤噪音\n\n3. 数据入库：将解析后的数据存储到PostgreSQL数据库\n   - 原理：PostgreSQL是关系型数据库，支持复杂查询和事务，适合存储结构化性能数据；使用批量插入提高效率\n   - 比喻：就像将整理好的数据存入仓库，方便后续查询\n\n4. 数据组织：按时间、按进程、按指标等维度组织数据\n   - 原理：建立合理的表结构，按维度（时间、进程、指标）组织数据，支持多维度查询和分析\n   - 比喻：就像图书馆按分类、时间、作者组织书籍，方便查找\n\n5. 查询优化：建立索引，优化查询性能\n   - 原理：在常用查询字段（如时间、进程ID）上建立索引，可以大幅提升查询速度（从O(n)降到O(log n)）\n   - 比喻：就像给字典加目录，快速定位\n\n6. 前端展示：使用ECharts和Grafana构建看板，展示性能数据\n   - 原理：ECharts是图表库，Grafana是可视化平台，可以从数据库读取数据并绘制图表，实时展示性能趋势\n   - 比喻：就像用仪表盘展示数据，直观易懂",
            "项目经历-性能看板"
        )

        self.add_card(
            "基线自动管理项目中，如何实现灵活的指标格式和自定义公式？",
            "1. 指标格式：支持多种指标格式（数值、百分比、时间等）\n   - 原理：定义指标格式枚举，每种格式有对应的解析和显示逻辑，支持格式转换和验证\n   - 比喻：就像支持多种单位（米、厘米、英寸），可以相互转换\n\n2. 自定义公式：允许用户定义计算公式，支持复杂的指标计算\n   - 原理：使用表达式解析器（如AST解析），将用户输入的公式字符串解析为语法树，支持变量、函数、运算符，动态计算\n   - 比喻：就像Excel的公式功能，用户可以写公式，系统自动计算\n\n3. 配置管理：通过配置文件定义指标和公式\n   - 原理：使用配置文件（如YAML、JSON）定义指标和公式，系统启动时加载配置，支持热更新，无需修改代码\n   - 比喻：就像用配置文件定义规则，修改配置即可，不需要改代码\n\n4. 自动计算：系统自动根据公式计算指标值\n   - 原理：系统定期或事件触发时，根据配置的公式自动计算指标值，支持依赖其他指标的计算\n   - 比喻：就像自动计算器，输入公式和变量，自动得出结果\n\n5. 基线对比：将当前指标值与基线对比，判断是否劣化\n   - 原理：基线是历史正常值，当前值与基线对比，计算偏差，超过阈值（如10%）判定为劣化\n   - 比喻：就像用标准线对比，超过标准线就报警\n\n6. 自动化测试：使用Pytest编写测试用例，100%覆盖用户场景\n   - 原理：Pytest是Python测试框架，编写测试用例覆盖所有功能场景，确保代码质量和功能正确性\n   - 比喻：就像用自动化测试代替人工测试，全面覆盖",
            "项目经历-基线管理"
        )

    def generate_soc_power_cards(self):
        ""生成SoC功耗优化相关的卡片""

        self.add_card(
            "WFI状态的进入和退出条件是什么？",
            "进入条件：任务队列为空，核心进入空闲状态\n- 原理：调度器检查任务队列，如果没有可运行的任务，核心进入空闲状态，自动进入WFI状态以节省功耗\n- 比喻：就像工人完成所有任务后，进入待命状态\n\n退出条件：收到中断信号（定时器中断、设备中断等）\n- 原理：中断控制器检测到中断事件，唤醒WFI状态的核心，核心立即响应中断，执行中断处理程序\n- 比喻：就像待命的工人收到通知，立即开始工作\n\n特点：核心暂停，但可以快速响应中断，功耗较低但核心仍保持供电\n- 原理：WFI是硬件指令，核心暂停执行但保持供电和时钟，中断响应延迟极低（微秒级），适合需要快速响应的场景\n- 比喻：就像待命的消防员，虽然不工作但随时准备，收到警报立即出动",
            "SoC功耗-CPU状态"
        )

        self.add_card(
            "WFE（Wait For Event）指令的工作原理是什么？",
            "WFE是ARM架构中让PE（Processing Element）进入low-power standby状态的指令。\n\n工作原理：\n1. Event Register机制：每个PE有一个单bit的Event Register\n   - 原理：Event Register是硬件寄存器，用于记录是否有事件发生；执行WFE时，会检查这个寄存器的状态\n   - 比喻：就像每个工人有一个待办事项标记，有标记就说明有事要做\n\n2. WFE执行逻辑：\n   - 如果Event Register为1：清零Event Register，然后执行完成（不会standby）\n     * 原理：有事件待处理，不需要进入低功耗状态，直接处理事件\n     * 比喻：就像有任务待办，不需要休息，直接工作\n   - 如果Event Register为0：进入low-power standby state，直到有WFE Wakeup events发生\n     * 原理：没有事件，进入低功耗状态等待事件\n     * 比喻：就像没有任务，进入待命状态\n\n3. 唤醒机制：\n   - WFE Wakeup events：包括IRQ中断、FIQ中断等，与WFI类似\n   - SEV指令唤醒：WFE可以被任何PE上执行的SEV（Send Event）指令唤醒\n     * 原理：SEV指令会修改所有PE的Event Register，将值设为1，从而唤醒处于WFE状态的PE\n     * 比喻：就像广播通知，所有待命的工人都能收到\n\n4. SEV指令类型：\n   - SEV：修改所有PE上的Event Register\n   - SEVL：只修改本PE的Event Register值\n   - 原理：SEV用于跨核心唤醒，SEVL用于本核心自唤醒\n   - 比喻：就像全局广播和本地通知的区别",
            "SoC功耗-CPU状态"
        )

        self.add_card(
            "WFE和WFI的区别是什么？",
            "共同点：\n1. 都是让ARM核进入low-power standby模式的指令\n   - 原理：两者都能让PE暂停执行，进入低功耗状态，节省功耗\n   - 比喻：就像两种不同的休息方式，都能节省体力\n\n2. 都由ARM architecture定义，由ARM core实现\n   - 原理：是ARM架构的标准指令，不同ARM核心可能有不同的实现方式（standby、dormant、shutdown等）\n   - 比喻：就像标准操作流程，不同工厂可能有不同的实现细节\n\n3. 都不能造成内存一致性问题\n   - 原理：进入低功耗状态时，必须保证缓存一致性，不能丢失数据\n   - 比喻：就像休息时不能丢失工作进度\n\n不同点：\n1. 进入方式：\n   - WFI：执行后立即进入standby状态\n     * 原理：WFI无条件进入低功耗状态，等待中断唤醒\n     * 比喻：就像直接进入待命状态\n   - WFE：根据Event Register状态决定是否进入standby\n     * 原理：如果Event Register为1，清零后不进入standby；如果为0，才进入standby\n     * 比喻：就像先检查待办事项，有任务就不休息，没任务才休息\n\n2. 唤醒方式：\n   - WFI：只能由硬件事件唤醒（中断等）\n     * 原理：WFI只能被硬件中断唤醒，是硬件行为\n     * 比喻：就像只能被硬件警报唤醒\n   - WFE：除了硬件事件，还可以被SEV指令唤醒\n     * 原理：WFE可以被软件指令（SEV）唤醒，提供了软件控制的灵活性\n     * 比喻：就像既可以被硬件警报唤醒，也可以被软件通知唤醒\n\n3. 使用场景：\n   - WFI：一般用于cpuidle\n     * 原理：cpuidle需要等待中断唤醒，WFI适合这种场景\n     * 比喻：就像系统空闲时等待中断\n   - WFE：典型用于spinlock中\n     * 原理：spinlock等待锁释放时，可以使用WFE进入低功耗，锁释放时用SEV唤醒，节省功耗\n     * 比喻：就像等待资源时进入待命，资源可用时被唤醒",
            "SoC功耗-CPU状态"
        )

        self.add_card(
            "WFE在spinlock中的应用场景是什么？",
            "WFE在spinlock中的应用可以节省功耗，避免busy loop。\n\n使用流程：\n1. 资源空闲：初始状态，资源可用\n   - 原理：锁处于未锁定状态，任何核心都可以获取\n   - 比喻：就像资源空闲，任何人都可以使用\n\n2. Core1获取锁：Core1访问资源，acquire lock，获得资源\n   - 原理：Core1通过原子操作（如LDREX/STREX）获取锁，设置锁为已占用状态\n   - 比喻：就像第一个工人获取资源，标记为已占用\n\n3. Core2等待锁：Core2访问资源，此时资源不空闲，执行WFE指令，让core进入low-power state\n   - 原理：Core2尝试获取锁失败，进入WFE状态等待，而不是busy loop，节省功耗\n   - 比喻：就像第二个工人发现资源被占用，进入待命状态等待，而不是一直检查\n\n4. Core1释放锁：Core1释放资源，release lock，同时执行SEV指令，唤醒Core2\n   - 原理：Core1释放锁时，通过SEV指令设置Event Register，唤醒等待的Core2\n   - 比喻：就像第一个工人释放资源，同时通知等待的工人\n\n5. Core2获取资源：Core2被唤醒，重新尝试获取锁，获得资源\n   - 原理：Core2从WFE状态唤醒，检查锁状态，如果可用则获取\n   - 比喻：就像等待的工人被唤醒，检查资源可用后获取\n\n优势：\n- 节省功耗：相比busy loop，WFE让核心进入低功耗状态，大幅降低功耗\n  * 原理：busy loop时核心持续运行，功耗高；WFE时核心暂停，功耗低\n  * 比喻：就像等待时休息而不是一直检查，节省体力\n- 快速响应：WFE状态可以快速唤醒，响应延迟低\n  * 原理：WFE是硬件指令，唤醒延迟低（微秒级），不会影响性能\n  * 比喻：就像待命状态可以快速响应，不会耽误工作\n\nARM64实现细节：\n- 在ARM64的spinlock实现中，arch_spin_unlock使用stlr指令释放锁\n  * 原理：stlr（Store-Release）指令在释放锁时，会触发global monitor状态变化，自动生成event，唤醒WFE中的CPU，无需显式调用SEV\n  * 比喻：就像释放锁时自动通知，不需要额外操作",
            "SoC功耗-CPU状态"
        )

        self.add_card(
            "游戏场景下CPU调度如何平衡性能和功耗？",
            "游戏场景有两个核心需求：快速响应需求和显示计算需求。系统通过CPU调度和调频协同工作来满足这两个需求。\n\n1. 快速响应需求：\n   - 需求特点：用户输入（触摸、按键）需要快速响应，延迟敏感（通常要求<16ms，对应60fps的帧时间）\n     * 原理：用户操作需要立即反馈，延迟过高会导致卡顿感，影响游戏体验\n     * 比喻：就像按按钮需要立即响应，延迟会让人感觉卡顿\n   - CPU调度策略：\n     * 预留核心：为输入处理预留1-2个核心（通常是小核），保证输入事件能立即处理\n       - 原理：预留核心可以避免输入事件等待核心唤醒，减少延迟；小核功耗低，适合常驻处理轻量级输入事件\n       - 比喻：就像预留一个快速通道，保证紧急事件能立即处理\n     * 快速唤醒：输入事件触发时，快速唤醒大核处理复杂逻辑\n       - 原理：输入事件可能触发复杂游戏逻辑（如技能释放、场景切换），需要大核的高性能；快速唤醒可以保证逻辑处理不延迟\n       - 比喻：就像收到紧急任务，立即唤醒高级工人处理\n     * 优先级调度：输入处理线程设置高优先级，优先调度\n       - 原理：调度器根据优先级分配CPU时间，高优先级任务优先执行，保证输入响应\n       - 比喻：就像VIP客户优先处理\n   - 调频策略：\n     * 快速提频：输入事件触发时，立即提升核心频率到高性能档位\n       - 原理：根据AOSP源码和schedutil Governor实现，调度器在分配任务前会通知cpufreq框架，提前提频；输入事件触发时，目标核心频率立即提升，避免任务等待频率提升\n       - 比喻：就像提前加速，任务到达时已经准备好高速运行\n     * 低延迟调频：使用schedutil等低延迟Governor，调频延迟<1ms\n       - 原理：schedutil集成在调度器中，使用实时负载信息，调频决策延迟低；传统Governor（如ondemand）需要采样统计，延迟较高（>10ms）\n       - 比喻：就像实时调节速度，不需要等待统计\n     * 频率下限：预留核心保持最低频率下限，避免降频过低影响响应\n       - 原理：频率过低会导致处理延迟增加，设置合理的频率下限可以保证基本响应速度\n       - 比喻：就像保持最低速度，避免太慢影响响应\n\n2. 显示计算需求：\n   - 需求特点：需要稳定的帧率（如60fps），每帧计算时间必须<16.67ms，持续计算能力要求高\n     * 原理：游戏需要稳定的帧率保证流畅度，帧率波动会导致卡顿；每帧的计算量可能很大（渲染、物理、AI等），需要持续的计算能力\n     * 比喻：就像生产线需要稳定速度，不能忽快忽慢\n   - CPU调度策略：\n     * 多核并行：唤醒多个核心（包括大核和小核）并行处理游戏逻辑和渲染\n       - 原理：游戏计算包括多个模块（游戏逻辑、物理计算、渲染准备等），可以并行处理；多核并行可以提高整体吞吐量，保证帧率稳定\n       - 比喻：就像多个工人同时工作，提高整体效率\n     * 负载均衡：通过CFS调度器在多个核心间均衡负载，避免单个核心过载\n       - 原理：CFS调度器监控各核心负载，将任务从过载核心迁移到负载较轻的核心，保证各核心负载均衡，避免瓶颈\n       - 比喻：就像合理分配工作量，避免某个工人过载\n     * 核心亲和性：游戏线程绑定到特定核心（通常是大核），避免频繁迁移\n       - 原理：核心迁移有开销（缓存失效、上下文切换），绑定核心可以减少迁移开销，提高性能；大核性能高，适合游戏主线程\n       - 比喻：就像固定工人到固定岗位，减少调动开销\n     * 持续运行：游戏主线程保持运行状态，避免进入WFI导致帧率下降\n       - 原理：游戏主线程需要持续运行，如果进入WFI会导致帧率下降；调度器保证游戏线程有足够的CPU时间\n       - 比喻：就像关键工人不能休息，需要持续工作\n   - 调频策略：\n     * 稳定频率：根据游戏负载设置稳定的目标频率，避免频繁调频\n       - 原理：频繁调频有延迟和功耗开销，稳定频率可以保证性能稳定；根据游戏负载（如战斗场景vs菜单场景）设置合理的频率档位\n       - 比喻：就像保持稳定速度，避免频繁变速\n     * 频率上限：设置合理的频率上限，避免过度提频导致功耗过高\n       - 原理：频率越高功耗越大（P ∝ f × V²），过度提频会导致功耗过高和发热；根据游戏实际需求设置合理的频率上限\n       - 比喻：就像设置最高速度限制，避免过度消耗\n     * 动态调整：根据游戏负载动态调整频率（战斗场景提频，菜单场景降频）\n       - 原理：游戏负载是动态的，不同场景计算量不同；调度器监控负载，动态调整频率，既保证性能又节省功耗\n       - 比喻：就像根据路况动态调整速度，上坡加速，下坡减速\n     * 协同调频：多个核心协同调频，保证整体性能\n       - 原理：游戏可能使用多个核心，需要协同调频；调度器和cpufreq框架协同工作，根据整体负载调整各核心频率\n       - 比喻：就像多个发动机协同工作，保证整体动力\n\n3. 调度和调频的协同：\n   - 调度器通知调频：调度器在分配任务前通知cpufreq框架，提前提频\n     * 原理：根据AOSP源码，调度器在分配任务到核心前，会通知cpufreq框架目标负载，cpufreq框架提前提频，避免任务等待频率提升\n     * 比喻：就像提前通知需要加速，任务到达时已经准备好\n   - 调频反馈调度：频率调整后，调度器根据实际频率调整调度策略\n     * 原理：频率影响核心性能，调度器需要根据实际频率调整任务分配；高频率核心可以处理更多任务，低频率核心适合轻量级任务\n     * 比喻：就像根据实际速度调整任务分配，快车多拉货，慢车少拉货\n   - 实时负载感知：schedutil Governor使用调度器的实时负载信息，实现精确调频\n     * 原理：schedutil集成在调度器中，直接使用调度器的负载信息（utilization），不需要采样统计，延迟低，精度高\n     * 比喻：就像直接使用实时工作量信息，不需要统计\n\n4. 功耗优化：\n   - 避免过度唤醒：不会无限制唤醒所有核心，保持合理的核心数量\n     * 原理：边际收益递减，核心越多性能提升越小，但功耗线性增加；根据游戏实际需求唤醒合理的核心数量（如2-4个核心）\n     * 比喻：就像不会为了稍微快一点就投入所有资源，要考虑性价比\n   - 动态降频：在保证性能的前提下，降低不必要的频率\n     * 原理：游戏负载是动态的，低负载场景（如菜单）可以降频节省功耗；但需要保证基本性能，不能影响响应\n     * 比喻：就像根据实际需求调整速度，不需要时减速省油\n   - 核心休眠：空闲核心进入WFI或Sleep状态，节省功耗\n     * 原理：游戏不需要所有核心，空闲核心可以进入低功耗状态；但需要快速唤醒能力，保证响应\n     * 比喻：就像不需要的工人可以休息，但需要时能立即上岗\n\n5. 总结：\n   - 快速响应需求：通过预留核心、快速唤醒、优先级调度和快速提频、低延迟调频来满足\n   - 显示计算需求：通过多核并行、负载均衡、持续运行和稳定频率、动态调整来满足\n   - 调度和调频协同工作，根据游戏负载动态调整，在保证性能的前提下优化功耗\n   - 原理：游戏场景需要同时满足快速响应和稳定帧率两个需求，系统通过CPU调度和调频的协同工作，在保证性能的前提下优化功耗\n   - 比喻：就像既要快速响应紧急任务，又要保证生产线稳定运行，需要合理调度和调节速度",
            "SoC功耗-调度策略"
        )

        self.add_card(
            "big.LITTLE架构的优势是什么？",
            "1. 性能核（大核）：处理计算密集型任务，保证性能\n   - 原理：大核设计为高性能（高频率、大缓存、多发射），适合处理计算密集型任务（如游戏、视频编码），保证性能\n   - 比喻：就像高性能跑车，速度快但耗油\n\n2. 效率核（小核）：处理轻量级任务，降低功耗\n   - 原理：小核设计为高能效（低频率、小缓存、简单流水线），适合处理轻量级任务（如UI刷新、后台服务），功耗低\n   - 比喻：就像节能汽车，省油但速度适中\n\n3. 动态切换：根据任务负载在大小核之间动态切换\n   - 原理：调度器根据任务特性（计算密集型还是轻量级）和负载，动态选择使用大核还是小核，实现性能和功耗的平衡\n   - 比喻：就像根据路况选择跑车还是节能车，高速用跑车，市区用节能车\n\n4. 功耗优化：在保证性能的前提下，最大化降低功耗\n   - 原理：大部分时间使用小核处理轻量级任务，功耗低；只在需要时使用大核，避免大核空转浪费功耗\n   - 比喻：就像大部分时间用节能车，需要时才用跑车，整体省油\n\n5. 适合移动设备：在有限的电池容量下提供最佳用户体验\n   - 原理：移动设备电池容量有限，big.LITTLE架构可以在保证性能的同时延长续航，提供最佳用户体验\n   - 比喻：就像在有限的燃料下，既保证速度又延长行驶距离",
            "SoC功耗-架构"
        )

        self.add_card(
            "big.LITTLE架构中大小核是如何实现的？为什么小核功耗低？",
            "big.LITTLE架构通过硬件层面的差异化设计实现大小核，小核功耗低主要源于简化的硬件架构和更低的运行参数。\n\n1. 大小核的实现原理：\n   - 硬件架构差异化设计：\n     * 大核（性能核）：采用高性能微架构设计\n       - 复杂的流水线结构：多级流水线（通常10-15级），支持乱序执行（Out-of-Order Execution）\n       - 大容量缓存：L1缓存通常32-64KB，L2缓存512KB-1MB，L3缓存共享\n       - 多发射执行单元：支持超标量（Superscalar）架构，每个时钟周期可以发射多条指令\n       - 丰富的执行单元：多个ALU、FPU、向量处理单元（NEON/SIMD）\n       - 高级分支预测：复杂的分支预测器，减少分支延迟\n       - 原理：大核通过复杂的硬件设计实现高性能，但硬件复杂度高，功耗大\n       - 比喻：就像高性能跑车，复杂的发动机和传动系统，速度快但耗油\n     * 小核（效率核）：采用高能效微架构设计\n       - 简化的流水线结构：较少的流水线级数（通常5-8级），顺序执行（In-Order Execution）\n       - 小容量缓存：L1缓存通常16-32KB，L2缓存128-256KB，无L3缓存或共享小容量L3\n       - 单发射或双发射：每个时钟周期发射1-2条指令\n       - 精简的执行单元：较少的ALU、FPU，可能没有或只有简单的向量处理单元\n       - 简单的分支预测：简单的分支预测器，降低硬件复杂度\n       - 原理：小核通过简化的硬件设计实现高能效，硬件复杂度低，功耗小\n       - 比喻：就像节能汽车，简单的发动机和传动系统，省油但速度适中\n\n2. 为什么小核功耗低（硬件设计角度）：\n   - 简化的微架构（Microarchitecture）：\n     * 顺序执行 vs 乱序执行：\n       - 大核：乱序执行需要复杂的指令调度器、重排序缓冲区（ROB）、保留站（Reservation Station）等，硬件复杂度高，功耗大\n       - 小核：顺序执行不需要复杂的调度硬件，指令按顺序执行，硬件简单，功耗低\n       - 原理：乱序执行需要大量硬件资源来跟踪和调度指令，顺序执行硬件需求少，功耗低\n       - 比喻：就像复杂的调度系统需要更多管理人员和资源，简单系统只需要基本人员\n     * 流水线级数：\n       - 大核：10-15级流水线，每级都需要硬件支持，功耗大\n       - 小核：5-8级流水线，级数少，硬件少，功耗低\n       - 原理：流水线级数越多，需要的流水线寄存器和控制逻辑越多，功耗越大\n       - 比喻：就像生产线越长，需要的设备和人员越多，消耗越大\n   - 小容量缓存：\n     * 缓存大小对比：\n       - 大核：L1缓存32-64KB，L2缓存512KB-1MB，L3缓存几MB\n       - 小核：L1缓存16-32KB，L2缓存128-256KB，无L3或小容量L3\n     * 功耗影响：\n       - 缓存是SRAM，需要持续供电保持数据\n       - 缓存容量越大，晶体管数量越多，静态功耗（漏电流）越大\n       - 缓存访问时，大缓存需要激活更多存储单元，动态功耗更大\n       - 原理：缓存功耗与容量成正比，大缓存功耗大，小缓存功耗小\n       - 比喻：就像大仓库需要更多电力和维护，小仓库消耗少\n   - 更少的执行单元：\n     * 执行单元数量：\n       - 大核：多个ALU（算术逻辑单元）、多个FPU（浮点单元）、向量处理单元（NEON/SIMD）\n       - 小核：较少的ALU、FPU，可能没有或只有简单的向量处理单元\n     * 功耗影响：\n       - 执行单元是功耗的主要来源之一\n       - 执行单元越多，并行执行能力越强，但功耗越大\n       - 小核通过减少执行单元降低功耗，但性能也降低\n       - 原理：执行单元需要大量晶体管，并行执行需要更多硬件，功耗大\n       - 比喻：就像多个工人同时工作，效率高但消耗大，少量工人效率低但消耗小\n   - 低频率运行：\n     * 频率对比：\n       - 大核：通常运行在1.5-3.0GHz的高频率\n       - 小核：通常运行在0.8-1.5GHz的低频率\n     * 功耗影响：\n       - 动态功耗公式：P_dynamic = C × V² × f，其中C是负载电容，V是电压，f是频率\n       - 频率越低，动态功耗越低（线性关系）\n       - 小核运行在低频率，动态功耗大幅降低\n       - 原理：频率与动态功耗成正比，低频率降低动态功耗\n       - 比喻：就像慢速行驶比高速行驶省油，频率低功耗低\n   - 低电压运行：\n     * 电压对比：\n       - 大核：需要高电压（通常0.9-1.2V）支持高频率运行\n       - 小核：可以在低电压（通常0.7-0.9V）下运行\n     * 功耗影响：\n       - 动态功耗与电压的平方成正比（P ∝ V²）\n       - 电压降低，功耗大幅降低（平方关系）\n       - 小核在低电压下运行，功耗显著降低\n       - 原理：电压对功耗的影响是平方关系，降低电压可以大幅降低功耗\n       - 比喻：就像降低工作强度，能耗大幅降低（平方关系）\n   - 简化的分支预测：\n     * 分支预测器复杂度：\n       - 大核：复杂的分支预测器（如两级自适应预测器、BTB等），需要大量硬件\n       - 小核：简单的分支预测器（如静态预测、简单动态预测），硬件需求少\n     * 功耗影响：\n       - 分支预测器需要额外的硬件和功耗\n       - 复杂的分支预测器功耗大，但预测准确率高，减少分支延迟\n       - 简单的分支预测器功耗小，但预测准确率低，可能增加分支延迟\n       - 原理：复杂的分支预测器需要更多硬件资源，功耗大\n       - 比喻：就像复杂的预测系统需要更多设备和计算，消耗大\n   - 更少的晶体管数量：\n     * 晶体管数量对比：\n       - 大核：通常包含数千万到上亿个晶体管\n       - 小核：通常包含数百万到数千万个晶体管，比大核少很多\n     * 功耗影响：\n       - 每个晶体管都有静态功耗（漏电流）和动态功耗（开关功耗）\n       - 晶体管数量越多，总功耗越大\n       - 小核晶体管数量少，总功耗低\n       - 原理：功耗与晶体管数量成正比，晶体管少功耗低\n       - 比喻：就像设备越多，总耗电越大，设备少耗电小\n\n3. 功耗对比数据：\n   - 典型功耗对比（同频率下）：\n     * 大核：通常几百毫瓦到几瓦（取决于频率和负载）\n     * 小核：通常几十毫瓦到几百毫瓦（取决于频率和负载）\n     * 功耗比：小核功耗通常是大核的1/5到1/10\n     * 原理：小核的简化设计和低运行参数使其功耗远低于大核\n     * 比喻：就像节能汽车和跑车的油耗对比，节能汽车油耗远低于跑车\n   - 能效比（性能/功耗）：\n     * 大核：高性能但高功耗，能效比中等\n     * 小核：中等性能但低功耗，能效比高\n     * 原理：小核通过牺牲部分性能换取高能效，适合轻量级任务\n     * 比喻：就像节能汽车虽然速度慢，但油耗低，能效比高\n\n4. 实际应用中的功耗优化：\n   - 任务分配策略：\n     * 轻量级任务（UI刷新、后台服务）→ 小核：功耗低，满足性能需求\n     * 计算密集型任务（游戏、视频编码）→ 大核：性能高，满足性能需求\n     * 原理：根据任务特性选择合适的核心，在满足性能需求的前提下最小化功耗\n     * 比喻：就像根据任务难度选择合适的工人，简单任务用小核，复杂任务用大核\n   - 动态切换：\n     * 调度器根据任务负载动态在大小核间切换\n     * 大部分时间使用小核，只在需要高性能时使用大核\n     * 原理：动态切换可以平衡性能和功耗，最大化能效\n     * 比喻：就像根据工作强度动态选择工人，大部分时间用小核，需要时才用大核",
            "SoC功耗-架构"
        )

        self.add_card(
            "同一个SOC中，有些核心使用32位指令集，有些核心使用64位指令集？",
            "是的，同一个SOC中的不同核心可以使用不同的指令集（32位或64位），这是异构多核架构的一种实现方式。虽然这种情况在实践中相对少见，但在技术上完全可行，并且已经有一些实际应用。\n\n1. 核心概念：\n   - ARMv8-A架构的执行状态：\n     * ARMv8-A架构支持两种执行状态（Execution State）：\n       - AArch64：64位执行状态，使用A64指令集，支持64位地址空间和64位数据处理\n       - AArch32：32位执行状态，使用A32和T32（Thumb）指令集，兼容ARMv7架构，支持32位地址空间\n     * 原理：ARMv8-A架构规范定义了两种执行状态，处理器可以支持其中一种或两种\n     * 比喻：就像汽车可以支持不同的驱动模式（32位模式和64位模式），但同一时刻只能使用一种模式\n   - 异构多核架构的指令集支持：\n     * 在big.LITTLE等异构架构中，不同核心可以有不同的指令集支持能力\n     * 例如：某些核心可能只支持32位（如Cortex-A32），某些核心可能同时支持32位和64位（如Cortex-A72、Cortex-A78）\n     * 原理：不同核心在硬件设计时可以独立选择支持的指令集，实现功能和成本的权衡\n     * 比喻：就像不同类型的工人可以掌握不同的技能（32位或64位），有些工人掌握一种技能，有些工人掌握两种技能\n\n2. 不同核心的指令集支持情况：\n   - 只支持32位的核心（AArch32 only）：\n     * 示例：ARM Cortex-A32核心只支持AArch32（32位）执行状态\n     * 特点：硬件简单，成本低，功耗低，但只支持32位应用程序\n     * 应用场景：嵌入式系统、IoT设备、成本敏感的应用，不需要64位功能\n     * 原理：只实现32位指令集可以减少硬件复杂度，降低成本和功耗，但限制了应用范围\n     * 比喻：就像只掌握32位技能的工人，装备简单，成本低，但只能做32位工作\n   - 同时支持32位和64位的核心（AArch64 + AArch32）：\n     * 示例：ARM Cortex-A72、Cortex-A78等核心同时支持AArch64和AArch32执行状态\n     * 特点：硬件复杂，成本高，功耗高，但可以运行32位和64位应用程序，兼容性好\n     * 应用场景：主流的移动设备、服务器等，需要兼容性和性能\n     * 原理：同时支持两种执行状态需要更多硬件资源（如寄存器文件、指令解码器等），但提供了最大的兼容性和灵活性\n     * 比喻：就像掌握两种技能的工人，装备复杂，成本高，但可以做32位和64位工作，适应性更强\n   - 只支持64位的核心（AArch64 only，理论上的可能）：\n     * 理论上可以设计只支持64位的核心，但在实际中很少见\n     * 原因：64位核心通常也会支持32位以确保兼容性，很少有只支持64位的核心\n     * 原理：只支持64位会失去对32位应用程序的兼容性，在实际应用中很少采用\n     * 比喻：就像只掌握64位技能的工人，虽然可能更高效，但失去了兼容性，实际应用中很少采用\n\n3. 为什么可以这样做（技术可行性）：\n   - 硬件独立设计：\n     * 每个核心在硬件上是完全独立的单元，可以独立设计和制造\n     * 不同核心可以有不同的指令集支持能力，包括寄存器文件、指令解码器、地址生成单元等\n     * 原理：核心是独立的硬件模块，指令集支持是核心设计的一部分，可以独立选择\n     * 比喻：就像不同类型的工人是独立的个体，可以掌握不同的技能（32位或64位）\n   - ARMv8-A架构规范的灵活性：\n     * ARMv8-A架构规范允许处理器实现只支持AArch32、只支持AArch64，或同时支持两者\n     * 芯片厂商可以根据需求选择实现的执行状态\n     * 原理：架构规范提供了灵活性，允许厂商根据应用场景选择合适的实现\n     * 比喻：就像规范允许选择不同的技能组合，厂商可以根据需求选择\n   - 执行状态的切换机制：\n     * 虽然同一核心在同一时刻只能运行一种执行状态（32位或64位），但支持两种执行状态的核心可以在异常边界切换\n     * 切换发生在异常级别（Exception Level）切换时，由硬件和软件协同管理\n     * 原理：执行状态切换需要保存和恢复寄存器状态，在异常边界进行可以保证状态一致性\n     * 比喻：就像切换工作模式需要在特定时刻（如交接班时）进行，保证状态一致\n   - 内存共享和缓存一致性：\n     * 虽然不同核心可能运行不同的执行状态（32位或64位），但它们可以共享相同的内存空间\n     * 通过缓存一致性协议（如MESI、MOESI、AMBA ACE），不同核心的缓存可以保持一致性\n     * 原理：内存地址空间是统一的，32位和64位核心可以访问相同的内存，缓存一致性协议保证数据一致\n     * 比喻：就像掌握不同技能的工人可以共享同一个工作空间和仓库，通过统一的管理系统保证数据一致",
            "SoC功耗-架构"
        )

        self.add_card(
            "一片64位的SoC上所有器件都一定支持64位指令集吗？GPU、NPU有没有32/64位指令集的概念？不同的指令集是否能集成到一片SoC上？",
            "不是的，一片64位的SoC上所有器件不一定都支持64位指令集。GPU、NPU、DSP等处理器有自己独特的指令集架构（ISA），不是简单的32/64位概念。不同的指令集完全可以集成到同一片SoC上，这是异构SoC架构的核心特性。\n\n1. 核心概念：\n   - SoC的\"64位\"通常指CPU支持64位指令集：\n     * 当说一个SoC是\"64位\"时，通常指的是CPU核心支持64位指令集（如ARMv8-A的AArch64）\n     * 但这不意味着SoC上的所有器件（GPU、NPU、DSP等）都必须支持64位指令集\n     * 原理：SoC是多个处理器的集合，每个处理器可以独立设计，使用不同的指令集\n     * 比喻：就像说一个工厂是\"现代化工厂\"（64位CPU），但工厂里的不同部门（GPU、NPU等）可以使用不同的工作方式（指令集），不一定都是现代化的\n   - GPU、NPU、DSP有自己的指令集概念：\n     * GPU（图形处理单元）：使用专有的图形指令集，针对并行计算和图形渲染优化\n     * NPU（神经网络处理单元）：使用自定义指令集，针对神经网络计算（矩阵运算、张量运算）优化\n     * DSP（数字信号处理器）：使用专门的信号处理指令集，如VLIW（超长指令字）架构\n     * 原理：不同处理器针对不同的应用场景优化，使用不同的指令集架构，不是简单的32/64位概念\n     * 比喻：就像不同专业的工人使用不同的工具和方法（指令集），不是简单的\"32位\"或\"64位\"概念\n\n2. GPU的指令集架构：\n   - GPU使用专有的图形指令集：\n     * ARM Mali GPU：使用专有的Mali指令集，基于Valhall等架构，针对图形渲染和并行计算优化\n     * Qualcomm Adreno GPU：使用专有的Adreno指令集，针对移动图形和计算优化\n     * 特点：GPU指令集不是简单的32/64位概念，而是针对并行计算、向量运算、图形渲染等任务优化的专有指令集\n     * 原理：GPU设计为并行处理器，指令集针对SIMD（单指令多数据）和并行执行优化，与CPU的通用指令集不同\n     * 比喻：就像图形设计师使用专门的绘图工具（GPU指令集），不是简单的\"32位\"或\"64位\"工具\n   - GPU指令集的特点：\n     * 针对并行计算：支持大量线程同时执行，指令集设计为并行友好\n     * 向量运算：支持SIMD指令，一条指令处理多个数据\n     * 图形特定操作：支持纹理采样、光栅化、着色等图形特定操作\n     * 原理：GPU指令集针对并行计算和图形处理优化，与CPU的通用指令集设计理念不同\n     * 比喻：就像专门的并行工作工具，可以同时处理多个任务\n   - GPU可以只支持32位或使用混合架构：\n     * 许多GPU使用32位数据路径和指令集，因为图形计算通常不需要64位精度\n     * 某些GPU可能支持64位浮点运算，但指令集本身不是简单的\"64位指令集\"概念\n     * 原理：GPU指令集设计针对图形和并行计算，数据宽度和指令集架构是独立的设计选择\n     * 比喻：就像图形工具可能使用32位精度就足够，不需要64位精度\n\n3. NPU的指令集架构：\n   - NPU使用自定义指令集，针对神经网络计算优化：\n     * 示例：Google Coral NPU基于32位RISC-V ISA，但添加了自定义的向量和矩阵执行引擎\n     * 特点：NPU指令集针对矩阵运算、张量运算、乘加运算（MAC）等神经网络核心操作优化\n     * 原理：NPU设计为神经网络加速器，指令集针对矩阵和张量运算优化，与CPU和GPU的指令集不同\n     * 比喻：就像AI专家使用专门的AI工具（NPU指令集），针对神经网络计算优化\n   - NPU指令集的特点：\n     * 矩阵运算指令：支持矩阵乘加、矩阵转置等操作\n     * 张量运算指令：支持多维张量的运算\n     * 数据类型支持：支持int8、int16等低精度数据类型，平衡精度和性能\n     * 原理：NPU指令集针对神经网络计算的核心操作优化，提供高效的矩阵和张量运算能力\n     * 比喻：就像专门的矩阵计算工具，可以高效处理矩阵运算\n   - NPU可以基于不同基础ISA：\n     * 某些NPU基于RISC-V ISA扩展（如Google Coral）\n     * 某些NPU使用完全自定义的ISA（如华为Ascend NPU）\n     * 某些NPU可能只支持32位或使用混合精度\n     * 原理：NPU ISA设计独立于CPU ISA，可以基于不同的基础架构，针对神经网络计算优化\n     * 比喻：就像AI工具可以基于不同的基础工具扩展，但都针对AI任务优化\n\n4. DSP的指令集架构：\n   - DSP使用专门的信号处理指令集：\n     * 示例：高通Hexagon DSP使用VLIW（超长指令字）架构，支持并行执行多条指令\n     * 特点：DSP指令集针对数字信号处理优化，如滤波、FFT、音频/视频编解码等\n     * 原理：DSP设计为信号处理加速器，指令集针对信号处理算法优化，与CPU、GPU、NPU的指令集不同\n     * 比喻：就像信号处理专家使用专门的信号处理工具（DSP指令集），针对信号处理优化\n   - DSP指令集的特点：\n     * VLIW架构：支持超长指令字，一条指令可以包含多个操作，并行执行\n     * 乘加运算：支持高效的乘加运算（MAC），这是信号处理的核心操作\n     * 数据类型：通常支持整数运算，某些DSP可能不支持浮点运算（如高通Hexagon DSP）\n     * 原理：DSP指令集针对信号处理算法优化，提供高效的信号处理能力\n     * 比喻：就像专门的信号处理工具，可以高效处理信号处理任务\n   - DSP可以只支持32位或使用特定架构：\n     * 许多DSP使用32位数据路径和指令集\n     * DSP指令集架构（如VLIW）与CPU的32/64位概念不同\n     * 原理：DSP指令集设计针对信号处理，数据宽度和指令集架构是独立的设计选择\n     * 比喻：就像信号处理工具可能使用32位精度和特定的并行架构就足够\n\n5. 不同指令集集成到同一片SoC的技术可行性：\n   - 硬件独立设计：\n     * CPU、GPU、NPU、DSP在硬件上是完全独立的单元，可以独立设计和制造\n     * 每个处理器可以有自己的指令集架构、寄存器文件、执行单元等\n     * 原理：不同处理器是独立的硬件模块，指令集架构是处理器设计的一部分，可以独立选择\n     * 比喻：就像工厂的不同部门是独立的，可以使用不同的工具和方法（指令集）\n   - 系统级互连：\n     * 不同处理器通过系统总线（如AMBA、AXI）互连，共享内存和外设\n     * 互连协议保证不同处理器可以访问相同的内存空间，即使使用不同的指令集\n     * 原理：系统总线提供统一的互连接口，不同处理器通过总线通信，指令集差异不影响互连\n     * 比喻：就像不同部门通过统一的工作网络连接，可以共享资源，即使使用不同的工具\n   - 内存共享和地址空间：\n     * 不同处理器可以共享相同的内存空间，通过统一的地址映射访问\n     * CPU使用虚拟地址空间，GPU、NPU、DSP可能使用物理地址或设备地址空间\n     * IOMMU（输入输出内存管理单元）负责地址转换，实现内存共享\n     * 原理：内存是统一的物理资源，不同处理器可以访问，地址转换机制保证访问的正确性\n     * 比喻：就像不同部门可以访问同一个仓库，通过统一的管理系统（IOMMU）协调访问\n   - 驱动和软件抽象：\n     * 操作系统和驱动程序提供统一的接口，抽象不同处理器的指令集差异\n     * 应用程序通过标准API（如OpenGL、Vulkan、OpenCL）使用GPU，不需要了解GPU的具体指令集\n     * 原理：软件抽象层隐藏了硬件细节，应用程序不需要直接处理不同处理器的指令集差异\n     * 比喻：就像通过统一的工作接口，不需要了解每个部门的具体工具和方法\n\n6. 实际应用中的情况：\n   - 典型的64位SoC配置：\n     * CPU：支持64位指令集（ARMv8-A AArch64），可能同时支持32位（AArch32）\n     * GPU：使用专有的图形指令集，可能只支持32位数据路径，或使用混合精度\n     * NPU：使用自定义指令集，可能基于32位RISC-V扩展，或完全自定义\n     * DSP：使用专门的信号处理指令集（如VLIW），通常支持32位数据路径\n     * 原理：不同处理器针对不同应用场景优化，使用不同的指令集，不需要都支持64位\n     * 比喻：就像工厂的不同部门使用不同的工具，不需要都是\"64位\"工具\n   - 实际示例：\n     * 高通Snapdragon SoC：\n       - CPU：ARM Cortex-A系列，支持64位指令集（AArch64）\n       - GPU：Adreno GPU，使用专有的Adreno指令集\n       - DSP：Hexagon DSP，使用VLIW架构，32位数据路径，不支持浮点运算\n       - NPU：可能集成AI加速器，使用自定义指令集\n     * 原理：不同处理器使用不同的指令集，针对各自的应用场景优化\n     * 比喻：就像高通工厂的不同部门使用不同的工具和方法\n   - GPU只支持32位指令集的情况：\n     * 许多移动GPU使用32位数据路径和指令集，因为图形计算通常不需要64位精度\n     * GPU指令集不是简单的\"32位指令集\"概念，而是针对图形和并行计算优化的专有指令集\n     * 原理：GPU设计针对图形渲染和并行计算，32位精度通常足够，不需要64位指令集\n     * 比喻：就像图形工具使用32位精度就足够，不需要64位精度\n\n7. 为什么GPU、NPU、DSP不需要支持64位指令集：\n   - 应用场景不同：\n     * GPU：主要用于图形渲染和并行计算，32位浮点精度通常足够\n     * NPU：主要用于神经网络推理，通常使用低精度数据类型（int8、int16）以平衡精度和性能\n     * DSP：主要用于信号处理，32位整数或浮点精度通常足够\n     * 原理：不同处理器的应用场景不同，对数据精度的需求不同，不需要都支持64位\n     * 比喻：就像不同专业的工具对精度的需求不同，图形工具和AI工具不需要64位精度\n   - 功耗和面积考虑：\n     * 支持64位指令集需要更多的硬件资源（寄存器文件、执行单元等），增加功耗和面积\n     * GPU、NPU、DSP针对特定应用优化，使用32位或混合精度可以在满足需求的同时降低功耗和面积\n     * 原理：64位指令集需要更多硬件资源，对于不需要64位精度的应用，使用32位可以节省功耗和面积\n     * 比喻：就像使用32位工具可以节省成本和空间，如果32位精度足够的话\n   - 性能优化：\n     * 32位数据路径可以支持更高的并行度，因为可以在相同面积内实现更多的执行单元\n     * GPU、NPU、DSP通过并行执行提高性能，32位数据路径有助于提高并行度\n     * 原理：32位数据路径可以在相同面积内实现更多执行单元，提高并行度和性能\n     * 比喻：就像使用32位工具可以在相同空间内放置更多工具，提高并行工作效率\n\n8. 技术挑战和解决方案：\n   - 数据格式转换：\n     * 挑战：CPU使用64位数据，GPU使用32位数据，需要数据格式转换\n     * 解决方案：驱动程序和运行时系统自动处理数据格式转换，对应用程序透明\n     * 原理：软件层自动处理数据格式转换，应用程序不需要关心底层数据格式差异\n     * 比喻：就像自动转换工具，将64位数据转换为32位数据，对用户透明\n   - 内存管理：\n     * 挑战：不同处理器使用不同的地址空间和内存管理方式\n     * 解决方案：IOMMU统一管理地址转换，实现内存共享和隔离\n     * 原理：IOMMU提供统一的地址转换机制，不同处理器可以访问相同的内存\n     * 比喻：就像统一的内存管理系统，协调不同处理器的内存访问\n   - 编程模型：\n     * 挑战：不同处理器使用不同的指令集，编程模型不同\n     * 解决方案：使用标准API（如OpenGL、Vulkan、OpenCL）抽象硬件差异，提供统一的编程接口\n     * 原理：标准API隐藏了硬件细节，提供统一的编程接口，简化开发\n     * 比喻：就像统一的工作接口，隐藏了不同部门的工具差异\n\n9. 总结：\n   - 核心答案：\n     * 不是的，一片64位的SoC上所有器件不一定都支持64位指令集\n     * GPU、NPU、DSP有自己独特的指令集架构，不是简单的32/64位概念\n     * 不同的指令集完全可以集成到同一片SoC上，这是异构SoC架构的核心特性\n     * 原理：SoC是多个处理器的集合，每个处理器可以独立设计，使用不同的指令集，针对不同的应用场景优化\n   - GPU、NPU、DSP的指令集特点：\n     * GPU：使用专有的图形指令集，针对并行计算和图形渲染优化，可能只支持32位数据路径\n     * NPU：使用自定义指令集，针对神经网络计算优化，可能基于32位RISC-V扩展或完全自定义\n     * DSP：使用专门的信号处理指令集（如VLIW），通常支持32位数据路径\n     * 原理：不同处理器针对不同应用场景优化，使用不同的指令集架构，不是简单的32/64位概念\n   - 技术可行性：\n     * 硬件独立设计：每个处理器可以独立选择指令集架构\n     * 系统级互连：通过系统总线连接，共享内存和外设\n     * 内存共享：通过IOMMU实现内存共享和地址转换\n     * 软件抽象：通过标准API抽象硬件差异\n     * 原理：通过硬件独立设计、系统互连、内存管理和软件抽象，实现不同指令集的处理器协同工作\n   - 实际应用：\n     * 典型的64位SoC：CPU支持64位指令集，GPU、NPU、DSP使用各自的专有指令集，可能只支持32位数据路径\n     * GPU可以只支持32位指令集，这在移动GPU中很常见\n     * 不同指令集的处理器可以集成到同一片SoC上，这是实际应用中的常见情况\n     * 原理：根据不同处理器的应用场景和需求，选择合适的指令集，实现性能和功耗的平衡\n   - 优势：\n     * 针对应用优化：每个处理器使用最适合的指令集，针对各自的应用场景优化\n     * 功耗和面积优化：使用32位或混合精度可以节省功耗和面积\n     * 性能优化：32位数据路径可以支持更高的并行度\n     * 原理：异构指令集设计提供了灵活性和优化空间，可以根据应用需求选择合适的指令集\n   - 原理：一片64位的SoC上所有器件不一定都支持64位指令集。GPU、NPU、DSP等处理器有自己独特的指令集架构（ISA），不是简单的32/64位概念。GPU使用专有的图形指令集，NPU使用自定义的神经网络指令集，DSP使用专门的信号处理指令集。不同的指令集完全可以集成到同一片SoC上，通过硬件独立设计、系统级互连、内存共享和软件抽象实现。这种异构指令集设计可以根据应用需求选择合适的指令集，实现性能和功耗的平衡。在实际应用中，GPU可以只支持32位指令集，这在移动GPU中很常见\n   - 比喻：就像一个现代化工厂（64位SoC），工厂的主控部门（CPU）使用现代化工具（64位指令集），但图形部门（GPU）使用专门的绘图工具（图形指令集），AI部门（NPU）使用专门的AI工具（神经网络指令集），信号处理部门（DSP）使用专门的信号处理工具（信号处理指令集）。这些工具不是简单的\"32位\"或\"64位\"概念，而是针对各自专业领域优化的专门工具。虽然使用不同的工具，但通过统一的工作网络（系统总线）和仓库（内存）连接，可以协同工作，完成复杂的任务",
            "SoC功耗-架构"
        )

        self.add_card(
            "如何评估软件层面的功耗优化效果？",
            "1. 功耗板对比：与硬件功耗测试设备的测量结果对比\n   - 原理：功耗板是专业的硬件测量设备，精度高，作为标准参考；软件计算结果与功耗板对比，验证准确性\n   - 比喻：就像用标准砝码校准天平，确保测量准确\n\n2. 数据采集：通过PMIC或Gauge获取电流数据，乘以电压（4V）得到功耗\n   - 原理：PMIC/Gauge可以实时测量电流，乘以电压（电池电压约4V）得到功耗（P=U×I）；软件通过读取这些数据计算功耗\n   - 比喻：就像用电流表和电压表计算功率\n\n3. 场景测试：在不同场景（游戏、视频、待机等）下测试\n   - 原理：不同场景的功耗特征不同，需要全面测试，覆盖各种使用场景，确保优化效果普遍有效\n   - 比喻：就像在不同路况下测试油耗，确保优化效果全面\n\n4. 版本对比：对比优化前后的功耗数据\n   - 原理：在相同场景下对比优化前后的功耗，计算优化幅度，验证优化效果\n   - 比喻：就像对比优化前后的油耗，看节省了多少\n\n5. 误差控制：确保软件计算误差在可接受范围内（通常10%以内）\n   - 原理：软件计算存在误差（如采样误差、计算误差），需要控制在可接受范围内（10%），确保数据可靠性\n   - 比喻：就像允许测量有10%的误差，在这个范围内认为合格",
            "SoC功耗-优化方法"
        )

        self.add_card(
            "功耗板是如何采集功耗数据的？",
            "1. 采集位置：通过物理连接测量整机或特定模块的电流和电压\n   - 原理：功耗板通过物理连接（如串联在电源回路中）直接测量电流，通过并联测量电压，这是最准确的测量方式\n   - 比喻：就像用电流表和电压表直接测量电路，最准确\n\n2. 数据来源：从PMIC（电源管理集成电路）或电池管理芯片获取电流数据\n   - 原理：PMIC和电池管理芯片内部有电流传感器，可以测量电流；功耗板通过接口读取这些数据\n   - 比喻：就像从专业仪器读取数据，精度高\n\n3. 折算方式：功耗板测量的是电流值（单位：mA），需要乘以电压（通常是4V，即电池电压）来得到功耗值（单位：mW）\n   - 原理：根据功率公式P=U×I，电流乘以电压得到功率；电池电压约4V（3.7V-4.4V），取4V作为典型值\n   - 比喻：就像用电流和电压计算功率，就像计算电器的耗电量\n\n公式：功耗 = 电流 × 电压 = mA × 4V = mW\n- 原理：这是电功率的基本公式，单位换算：mA（毫安）×V（伏特）=mW（毫瓦）\n- 比喻：就像计算功率的标准公式",
            "SoC功耗-测量方法"
        )

        self.add_card(
            "DVFS（Dynamic Voltage and Frequency Scaling）的工作原理是什么？",
            "DVFS是动态电压频率调节技术：\n\n1. 原理：根据负载动态调节CPU的电压和频率\n   - 原理：CPU负载高时提高频率和电压保证性能，负载低时降低频率和电压节省功耗；这是动态的，实时调整\n   - 比喻：就像根据工作量调整工作速度和强度，忙时加速，闲时减速\n\n2. 功耗关系：功耗与频率和电压的平方成正比（P ∝ f × V²）\n   - 原理：CMOS电路的动态功耗公式，频率越高、电压越高，功耗越大；电压的平方关系意味着降低电压对功耗影响更大\n   - 比喻：就像速度越快、用力越大，消耗越多；而且用力（电压）的影响是平方关系，影响更大\n\n3. 策略：\n   - 高负载：提高频率和电压，保证性能\n     * 原理：高负载需要高频率处理，高频率需要高电压保证稳定性，牺牲功耗换取性能\n     * 比喻：就像重活需要快速度和大力气\n   - 低负载：降低频率和电压，降低功耗\n     * 原理：低负载不需要高频率，可以降低频率和电压，大幅降低功耗\n     * 比喻：就像轻活可以慢速度和省力气\n\n4. 调频延迟：频率切换需要一定时间（通常几微秒到几十微秒）\n   - 原理：频率切换需要时钟发生器重新锁定，需要时间；延迟会影响实时性，需要权衡\n   - 比喻：就像换挡需要时间，不能瞬间切换\n\n5. 调压延迟：电压切换需要更长时间，需要等待电压稳定\n   - 原理：电压切换需要电压调节器调整，需要等待电压稳定，时间比调频更长（几十微秒到几百微秒）\n   - 比喻：就像调整电压比调整速度更慢，需要等待稳定",
            "SoC功耗-DVFS"
        )

        self.add_card(
            "什么是热节流（Thermal Throttling）？",
            "热节流是当芯片温度过高时，系统自动降低性能以降低功耗和温度的保护机制。\n\n触发条件：\n1. 温度传感器检测到温度超过阈值\n   - 原理：SoC内部有温度传感器，实时监测芯片温度，超过阈值（如85°C）触发保护机制\n   - 比喻：就像温度计检测到过热，触发保护\n\n2. 系统自动降低CPU频率\n   - 原理：降低频率可以降低功耗，从而降低温度；这是最常用的方法\n   - 比喻：就像降低发动机转速，减少发热\n\n3. 可能关闭部分核心\n   - 原理：关闭部分核心可以大幅降低功耗和温度，但性能下降明显\n   - 比喻：就像关闭部分发动机，减少发热但动力下降\n\n4. 降低GPU频率\n   - 原理：GPU也是发热大户，降低GPU频率可以降低温度\n   - 比喻：就像降低显卡频率，减少发热\n\n影响：\n- 性能下降：用户体验可能受到影响\n  * 原理：降频和关闭核心会导致性能下降，用户可能感觉到卡顿\n  * 比喻：就像限速后速度变慢\n- 功耗降低：温度下降，保护硬件\n  * 原理：降低功耗后温度下降，保护芯片不被烧毁\n  * 比喻：就像降温后保护设备\n\n优化：通过合理的温控策略，在性能和温度之间平衡\n- 原理：设置合理的温度阈值和降频策略，既保护硬件又尽量减少对性能的影响\n- 比喻：就像设置合理的温度控制，既保护设备又保证性能",
            "SoC功耗-热管理"
        )

        self.add_card(",
            "CPU Governor的数据来源是什么？",
            "SoC功耗-调频策略",
            "SoC功耗-调频策略"
        )

        self.add_card(",
            "Android中interactive和schedutil调频策略的对比和配置架构是什么？",
            "SoC功耗-调频策略",
            "SoC功耗-调频策略"
        )

        self.add_card(",
            "CPU Performance Scaling（CPU性能调节）的系统性介绍是什么？",
            "SoC功耗-调频机制",
            "SoC功耗-调频机制"
        )

        self.add_card(
            "cpufreq子系统、Governor和CPU Driver之间的关系是什么？",
            "cpufreq子系统、Governor和CPU Driver是Linux内核CPU频率管理系统的三个核心组件，它们通过分层架构协同工作，实现CPU频率的动态调节（架构组成和工作流程参见\"CPU Performance Scaling（CPU性能调节）的系统性介绍\"）。\n\n1. 三层架构关系：\n   - cpufreq子系统（核心框架层）：\n     * 位置：Linux内核的cpufreq子系统（drivers/cpufreq/）\n     * 角色：中间层，提供统一的频率调节接口和框架\n     * 功能：\n       - 提供统一的API接口（如cpufreq_set_policy、cpufreq_update_policy）\n       - 管理频率表（Frequency Table）和OPP（Operating Performance Point）\n       - 协调Governor和Driver之间的交互\n       - 管理调频策略（policy）和频率限制\n     * 原理：cpufreq是内核子系统，在内核空间运行，作为Governor和Driver之间的桥梁，提供统一的抽象层\n     * 比喻：就像统一的管理中心，协调策略制定者（Governor）和执行者（Driver）\n   - CPU Governor（策略决策层）：\n     * 位置：cpufreq子系统内的策略模块（如drivers/cpufreq/governors/）\n     * 角色：上层策略模块，决定何时以及如何调节频率\n     * 功能：\n       - 监控系统负载（CPU利用率、任务队列长度等）\n       - 根据负载和策略算法决定目标频率\n       - 通过cpufreq核心框架的接口设置目标频率\n     * 类型：performance、powersave、ondemand、conservative、interactive、schedutil等\n     * 原理：Governor是策略模块，只负责决策，不直接操作硬件；通过cpufreq核心框架的接口与Driver通信\n     * 比喻：就像决策层（总经理），根据市场情况（负载）决定生产速度（频率），但不直接操作机器\n   - CPU Driver（硬件执行层）：\n     * 位置：针对不同CPU架构的驱动（如drivers/cpufreq/cpufreq-dt.c、drivers/cpufreq/intel_pstate.c）\n     * 角色：底层驱动模块，实际执行频率调节\n     * 功能：\n       - 接收cpufreq核心框架传递的目标频率\n       - 通过寄存器或接口与PMU（电源管理单元）通信\n       - 控制时钟发生器（Clock Generator）改变CPU频率\n       - 控制电压调节器（Voltage Regulator）改变CPU电压\n       - 验证频率表，确保频率-电压组合有效\n     * 类型：针对不同CPU架构（如ARM的cpufreq-dt、Intel的intel_pstate、高通的cpufreq-qcom）\n     * 原理：Driver是硬件特定的实现，封装了不同CPU架构的调频方式，通过cpufreq核心框架的接口与Governor通信\n     * 比喻：就像执行层（工人），根据决策层（Governor）的指示，实际操作机器（硬件）改变速度（频率）\n\n2. 接口和通信机制：\n   - cpufreq核心框架接口：\n     * 提供给Governor的接口：\n       - cpufreq_driver_target：设置目标频率\n       - cpufreq_update_policy：更新调频策略\n       - cpufreq_frequency_table_verify：验证频率表\n     * 提供给Driver的接口：\n       - cpufreq_frequency_table_cpuinfo：注册频率表\n       - cpufreq_frequency_table_target：查找目标频率\n       - cpufreq_notify_transition：通知频率转换\n     * 原理：核心框架提供双向接口，Governor和Driver通过核心框架间接通信，实现解耦\n     * 比喻：就像管理中心提供双向接口，决策层和执行层通过管理中心通信\n   - Governor接口（struct cpufreq_governor）：\n     * init：初始化Governor\n     * exit：退出Governor\n     * start：启动Governor\n     * stop：停止Governor\n     * limits：设置频率限制（min/max）\n     * target：设置目标频率（通过cpufreq核心框架）\n     * 原理：Governor实现标准接口，核心框架通过接口调用Governor，Governor通过接口与核心框架通信\n     * 比喻：就像决策层实现标准接口，管理中心通过接口调用决策层\n   - Driver接口（struct cpufreq_driver）：\n     * init：初始化驱动\n     * verify：验证频率表\n     * setpolicy/getpolicy：设置/获取调频策略（某些驱动支持）\n     * target：设置目标频率（实际执行频率调节）\n     * get：获取当前频率\n     * 原理：Driver实现标准接口，核心框架通过接口调用Driver，Driver通过接口与核心框架和硬件通信\n     * 比喻：就像执行层实现标准接口，管理中心通过接口调用执行层，执行层操作硬件\n\n3. 依赖关系：\n   - cpufreq核心框架是基础：\n     * 提供统一的接口和框架，Governor和Driver都依赖它\n     * 没有核心框架，Governor和Driver无法协同工作\n     * 原理：核心框架是中间层，提供了Governor和Driver之间的通信桥梁\n     * 比喻：就像管理中心是基础，没有它决策层和执行层无法协同\n   - Governor依赖cpufreq核心框架：\n     * Governor通过核心框架的接口设置目标频率\n     * Governor不知道Driver的具体实现，只关心接口\n     * 原理：Governor和Driver通过核心框架解耦，Governor不需要知道Driver的细节\n     * 比喻：就像决策层依赖管理中心，不需要知道执行层的细节\n   - Driver依赖cpufreq核心框架：\n     * Driver通过核心框架的接口接收目标频率\n     * Driver不知道Governor的具体实现，只关心接口\n     * 原理：Driver和Governor通过核心框架解耦，Driver不需要知道Governor的细节\n     * 比喻：就像执行层依赖管理中心，不需要知道决策层的细节\n   - Governor和Driver通过cpufreq核心框架间接通信：\n     * Governor不直接调用Driver，Driver不直接调用Governor\n     * 所有通信都通过cpufreq核心框架\n     * 原理：通过核心框架实现解耦，Governor和Driver可以独立开发和替换\n     * 比喻：就像决策层和执行层不直接通信，都通过管理中心\n\n5. 可替换性和灵活性：\n   - Governor可替换：\n     * 系统可以选择不同的Governor（如performance、ondemand、schedutil等）\n     * 不同Governor有不同的调频策略，但不影响Driver\n     * 原理：Governor和Driver解耦，更换Governor不需要修改Driver\n     * 比喻：就像可以更换决策层（总经理），不影响执行层（工人）\n   - Driver可替换：\n     * 针对不同CPU架构有不同的Driver（如ARM的cpufreq-dt、Intel的intel_pstate）\n     * 不同Driver有不同的硬件实现，但不影响Governor\n     * 原理：Driver和Governor解耦，更换Driver不需要修改Governor\n     * 比喻：就像可以更换执行层（不同工厂的工人），不影响决策层（总经理）\n   - 核心框架统一接口：\n     * 核心框架提供统一的接口，Governor和Driver都遵循接口规范\n     * 任何符合接口规范的Governor和Driver都可以协同工作\n     * 原理：统一接口实现了Governor和Driver的可替换性和互操作性\n     * 比喻：就像统一的管理规范，任何符合规范的决策层和执行层都可以协同\n\n6. 实际示例：\n   - 示例1：schedutil Governor + cpufreq-dt Driver（ARM平台）\n     * schedutil监控调度器负载，决定目标频率，通过cpufreq核心框架设置频率\n     * cpufreq-dt Driver接收目标频率，通过Device Tree配置的PMU接口调节频率\n     * 原理：schedutil作为Governor，cpufreq-dt作为Driver，通过cpufreq核心框架协同工作\n     * 比喻：就像智能决策层（schedutil）和ARM执行层（cpufreq-dt）通过管理中心协同\n   - 示例2：ondemand Governor + intel_pstate Driver（Intel平台）\n     * ondemand监控CPU利用率，决定目标频率，通过cpufreq核心框架设置频率\n     * intel_pstate Driver接收目标频率，通过Intel特定的MSR寄存器调节频率\n     * 原理：ondemand作为Governor，intel_pstate作为Driver，通过cpufreq核心框架协同工作\n     * 比喻：就像传统决策层（ondemand）和Intel执行层（intel_pstate）通过管理中心协同\n\n7. 与调度器的协作（以schedutil为例）：\n   - schedutil的特殊性：\n     * schedutil直接集成在调度器中（kernel/sched/cpufreq_schedutil.c）\n     * 可以直接访问调度器的负载信息，不需要通过cpufreq核心框架获取负载\n     * 但仍然通过cpufreq核心框架设置目标频率，调用Driver接口\n     * 原理：schedutil虽然集成在调度器中，但仍然遵循cpufreq架构，通过核心框架与Driver通信\n     * 比喻：就像决策层直接集成在工作调度中，但仍然通过管理中心与执行层通信\n   - 工作流程：\n     * 调度器计算CPU利用率（utilization）\n     * schedutil根据utilization计算目标频率\n     * schedutil通过cpufreq核心框架的接口（cpufreq_driver_target）设置目标频率\n     * cpufreq核心框架调用Driver的target接口\n     * Driver实际执行频率调节\n     * 原理：即使schedutil集成在调度器中，仍然遵循cpufreq的三层架构，通过核心框架与Driver通信\n     * 比喻：就像即使决策层集成在工作调度中，仍然通过管理中心与执行层通信\n\n8. 总结：\n   - 三层架构：\n     * cpufreq子系统（核心框架）：中间层，提供统一接口和协调机制\n     * Governor（策略决策层）：上层，决定何时以及如何调节频率\n     * CPU Driver（硬件执行层）：下层，实际执行频率调节\n   - 关系特点：\n     * 分层架构：Governor在上，cpufreq核心框架在中，Driver在下\n     * 间接通信：Governor和Driver通过cpufreq核心框架间接通信，不直接交互\n     * 解耦设计：Governor和Driver可以独立开发和替换，互不影响\n     * 统一接口：核心框架提供统一接口，Governor和Driver都遵循接口规范\n   - 工作流程：\n     * 负载监控（Governor）→ 频率决策（Governor）→ 频率请求（Governor → 核心框架）→ 请求验证和转发（核心框架）→ 频率调节（Driver）→ 验证和反馈（Driver → 核心框架）\n   - 优势：\n     * 灵活性：可以替换Governor或Driver，不影响其他组件\n     * 可扩展性：可以添加新的Governor或Driver，只要遵循接口规范\n     * 可维护性：分层架构清晰，各组件职责明确\n   - 原理：cpufreq子系统、Governor和CPU Driver通过分层架构和统一接口，实现了策略决策和硬件执行的分离，提供了灵活、可扩展、可维护的CPU频率管理机制\n   - 比喻：就像企业管理中的三层架构：决策层（Governor）根据市场情况（负载）决定生产速度（频率），通过管理中心（cpufreq核心框架）下达指令，执行层（Driver）实际操作机器（硬件）改变速度，三者通过统一的管理规范（接口）协同工作",
            "SoC功耗-调频机制"
        )

        self.add_card(
            "schedutil Governor的系统性介绍是什么？",
            "schedutil是Linux内核中基于调度器负载信息的CPU调频Governor，是cpufreq子系统中最智能和高效的调频策略。\n\n1. 核心概念：\n   - 定义：schedutil是直接使用调度器（CFS）负载信息的CPU调频Governor\n   - 特点：基于调度器的实时负载信息，调频更准确、更及时\n",
            "SoC功耗-调频策略"
        )

        self.add_card(",
            "C0、C1、C2、C3状态的详细特点是什么？",
            "SoC功耗-Idle状态",
            "SoC功耗-Idle状态"
        )

        self.add_card(",
            "调度器、CPUidle框架、Governor（包括schedutil）的协同关系是什么？",
            "Kernel调度-调度协作",
            "Kernel调度-调度协作"
        )

        self.add_card(",
            "CPU Idle与WFI、WFE的关系是什么？",
            "SoC功耗-CPU状态",
            "SoC功耗-CPU状态"
        )

        # 豆包对话：SoC架构与负载均衡
        self.add_card(",
            "多核心SOC架构下，不同处理器之间（CPU、GPU、DSP、NPU）的负载均衡是如何实现的？",
            "SoC功耗-负载均衡",
            "SoC功耗-负载均衡"
        )

        self.add_card(",
            "应用乱搞导致SoC负载爆满时，系统和硬件层面有哪些应对机制？",
            "SoC功耗-负载均衡",
            "SoC功耗-负载均衡"
        )

        # 豆包对话：CPU调频机制
        self.add_card(",
            "调频的幅度和具体数值是如何确定的？",
            "SoC功耗-调频机制",
            "SoC功耗-调频机制"
        )

        self.add_card(",
            "CPU从低功耗状态唤醒时的调频策略是什么？",
            "SoC功耗-调频机制",
            "SoC功耗-调频机制"
        )

        self.add_card(",
            "如何通过架构设计让CPU频率剧烈变化且安全？",
            "SoC功耗-调频机制",
            "SoC功耗-调频机制"
        )

        self.add_card(",
            "分布式管理机制包括哪些？",
            "SoC功耗-调频机制",
            "SoC功耗-调频机制"
        )

        self.add_card(",
            "PELT（Per-Entity Load Tracking）算法是什么？",
            "SoC功耗-调频机制",
            "SoC功耗-调频机制"
        )

        self.add_card(",
            "WALT（Window-Assisted Load Tracking）算法是什么？",
            "SoC功耗-调频机制",
            "SoC功耗-调频机制"
        )

        # 豆包对话：亮屏时CPU的Low Power Mode（详细补充）
        self.add_card(",
            "高通SoC在亮屏时CPU核心的四种状态（Active、WFI、Sleep、Deep Sleep）是什么？",
            "SoC功耗-CPU状态",
            "SoC功耗-CPU状态"
        )

        self.add_card(",
            "CPU状态转换的触发条件总结表是什么？",
            "SoC功耗-CPU状态",
            "SoC功耗-CPU状态"
        )

        self.add_card(",
            "各CPU状态下的功能限制是什么？",
            "SoC功耗-CPU状态",
            "SoC功耗-CPU状态"
        )

        # 豆包对话：功耗优化
        self.add_card(",
            "从软件层面降低功耗的方法有哪些？定位问题和解决手段是什么？"精准定位，按需优化\"：\n\n定位问题的方法：\n1. Power Profiler工具：能实时监测SOC各模块（比如CPU、GPU、Modem）的功耗、频率和负载，还能记录不同场景下的功耗曲线\n2. Perfetto工具：分析是哪个应用或进程在频繁调用GPU，或者GPU驱动有没有异常\n3. 内核trace日志：查看调度器的任务分配情况，看是否存在任务不合理集中导致某核心满载的情况\n\n解决手段：\n1. CPU功耗高：如果发现有很多小任务频繁唤醒CPU，可以优化应用的后台唤醒机制，比如合并定时任务，减少不必要的唤醒次数；调整调度器的Idle状态策略，让CPU在空闲时更快进入深度休眠\n2. GPU功耗高：比如游戏场景下，可以优化图形渲染流程，比如降低非关键场景的渲染分辨率；用GPU的动态帧率调节功能，在画面静态时自动降帧，动态时恢复高帧\n3. Modem功耗高：如果后台频繁联网，可以优化应用的网络请求策略，合并小数据包，减少网络唤醒次数",",
            "SoC功耗-优化方法"
        )

        self.add_card(
            "网络优化如何降低功耗？核心原理和优化方法是什么？",",
            "网络优化省功耗的核心，就是减少设备无线模块的唤醒次数和工作时间：\n\n核心原理和优化方法\n",
            "SoC功耗-优化方法"
        )

        self.add_card(",
            "Modem的位置有哪些？集成式和分离式有什么区别？",
            "SoC功耗-优化方法",
            "SoC功耗-优化方法"
        )

    def generate_soc_architecture_cards(self):
        ""生成SoC架构相关的卡片""

        self.add_card(",
            "ARM架构的缓存层级有哪些？各有什么特点？",
            "SoC架构-缓存",
            "SoC架构-缓存"
        )

        self.add_card(",
            "高通的System Level Cache（SLC）是什么？它如何与GPU共享？",
            "SoC架构-缓存",
            "SoC架构-缓存"
        )

        self.add_card(",
            "内存中一次取出的最小大小是多少KB？是否存在各种情况？",
            "SoC架构-缓存",
            "SoC架构-缓存"
        )

        self.add_card(",
            "DMA（直接内存访问）的作用是什么？",
            "SoC架构-DMA",
            "SoC架构-DMA"
        )

        self.add_card(",
            "DMA操作中的缓存一致性问题如何解决？",
            "SoC架构-DMA",
            "SoC架构-DMA"
        )

        self.add_card(",
            "DMA的优先级设置机制是什么？",
            "SoC架构-DMA",
            "SoC架构-DMA"
        )

        self.add_card(",
            "SLC（System Level Cache）和DMA（Direct Memory Access）有什么区别？",
            "SoC架构-缓存",
            "SoC架构-缓存"
        )

        self.add_card(",
            "SOC内部的总线架构有哪些类型？",
            "SoC架构-总线",
            "SoC架构-总线"
        )

        self.add_card(",
            "SOC中包含哪些主要模块？",
            "SoC架构-模块",
            "SoC架构-模块"
        )

        self.add_card(",
            "NoC（Network on Chip）架构的优势是什么？",
            "SoC架构-互连",
            "SoC架构-互连"
        )

        self.add_card(",
            "什么是缓存一致性（Cache Coherency）？",
            "SoC架构-缓存一致性",
            "SoC架构-缓存一致性"
        )

        self.add_card(",
            "缓存一致性（Cache Coherency）和NUMA（Non-Uniform Memory Access）有什么区别和联系？",
            "SoC架构-缓存一致性",
            "SoC架构-缓存一致性"
        )

        self.add_card(",
            "什么是内存屏障（Memory Barrier）？",
            "SoC架构-内存屏障",
            "SoC架构-内存屏障"
        )

        self.add_card(",
            "TLB（Translation Lookaside Buffer）的详细工作原理是什么？",
            "SoC架构-TLB",
            "SoC架构-TLB"
        )

        self.add_card(",
            "32位架构仅支持4GB内存，且2级页表意味着页表总大小是8KB。这些数字是如何计算出的？计算依据和原理是什么？这些数字一定都是固定的吗？",
            "32位架构支持4GB内存和2级页表总大小8KB都是基于特定的架构设计计算得出的，这些数字并非完全固定，可以根据架构设计而变化。\n\n1. 32位架构为什么仅支持4GB内存：\n   - 核心计算：\n     * 32位地址意味着地址总线有32位，可以表示2^32个不同的地址\n     * 每个地址对应1个字节（byte）\n     * 最大内存容量 = 2^32 字节 = 4,294,967,296 字节\n     * 转换为GB：4,294,967,296 字节 / (1024 × 1024 × 1024) = 4 GB\n",
            "操作系统基础-内存管理"

        self.add_card(
            "什么是预取（Prefetch）？有哪些类型？",",
            "预取是提前将数据加载到缓存中，以减少缓存miss。\n类型：\n1. 硬件预取：CPU自动预取，基于访问模式（顺序、步长等）\n2. 软件预取：程序员使用预取指令（如__builtin_prefetch）\n3. 预取策略：\n   - 顺序预取：预取连续地址\n   - 步长预取：预取固定步长的地址\n   - 指针追踪预取：预取指针指向的地址\n注意事项：\n- 预取可能浪费带宽和缓存空间\n- 需要预测访问模式\n- 预取延迟需要隐藏",
            "SoC架构-预取"
        )

        self.add_card(",
            "ARMv8-A是什么？为什么这个架构对ARM很重要？",
            "SoC架构-ARMv8",
            "SoC架构-ARMv8"
        )

        self.add_card(",
            "ARMv8-A架构的核心特点是什么？"ARMv8-A是什么？为什么这个架构对ARM很重要？\"）：\n\n1. 更大的寄存器文件：31个通用寄存器（64位）\n",",
            "SoC架构-ARMv8"
        )

        self.add_card(
            "ARMv8-A和AArch64的关系是什么？",",
            "ARMv8-A和AArch64是不同层面的概念，它们的关系需要从架构和执行状态两个维度理解。\n\n1. 概念层面的关系：\n   - ARMv8-A：\n     * 定义：ARM架构规范的第8个主要版本（v8），A表示Application profile（应用处理器）\n     * 性质：架构规范（Architecture Specification），定义了完整的架构特性\n"
            "SoC架构-ARMv8",
            "SoC架构-ARMv8"

        self.add_card(",
            "ARMv8-A中的PE（Processing Element）是什么？",
            "SoC架构-ARMv8",
            "SoC架构-ARMv8"
        )

        self.add_card(",
            "ARMv8-A架构中的执行状态（Execution State）有哪些？",
            "SoC架构-ARMv8",
            "SoC架构-ARMv8"
        )

        self.add_card(",
            "ARMv8-A架构中的异常级别（Exception Level）是什么？",
            "SoC架构-ARMv8",
            "SoC架构-ARMv8"
        )

        self.add_card(",
            "ARMv8-A架构中的内存管理有什么特点？",
            "SoC架构-ARMv8",
            "SoC架构-ARMv8"
        )

        self.add_card(",
            "ARMv9和ARMv8-A的主要区别是什么？",
            "ARMv9是ARM架构的第9个主要版本，在ARMv8-A的基础上引入了多项重要改进和新特性。\n\n1. 发布时间和定位：\n   - ARMv8-A：\n     * 发布时间：2011年发布\n     * 定位：64位架构的里程碑，首次支持64位\n",
            "SoC架构-ARMv8"

        # CPU性能指标
        self.add_card(
            "CPU时钟树的作用是什么？",",
            "CPU时钟树（Clock Tree）是SoC中用于生成和分配时钟信号的硬件结构，是CPU和整个SoC系统正常工作的基础。\n\n1. 定义和结构：\n   - 定义：时钟树是从时钟源（如晶振、PLL）到各个模块的时钟分配网络\n   - 结构：\n     * 时钟源：晶振（Oscillator）、PLL（Phase-Locked Loop）等\n     * 时钟分配网络：时钟缓冲器、时钟分频器、时钟门控等\n     * 时钟目标：CPU核心、GPU、内存控制器、外设等\n",
            "SoC架构-时钟"
        )

        self.add_card(",
            "CPU衡量性能的关键指标有哪些？",
            "SoC架构-性能指标",
            "SoC架构-性能指标"
        )

    def generate_trace_cards(self):
        ""生成systrace/ftrace相关的卡片""

        self.add_card(",
            "htrace/systrace可以显示哪些内容？",
            "Trace工具-systrace",
            "Trace工具-systrace"
        )

        self.add_card(",
            "解析Trace的看板通常是如何工作的？",
            "Trace工具-解析",
            "Trace工具-解析"
        )

        self.add_card(",
            "perf工具的来源和用法是什么？",
            "Trace工具-perf",
            "Trace工具-perf"
        )

        self.add_card(",
            "ftrace可以跟踪哪些内核事件？",
            "Trace工具-ftrace",
            "Trace工具-ftrace"
        )

        self.add_card(",
            "为什么ftrace使用前一定要挂载debugfs（或tracefs）？",
            "ftrace是Linux内核的跟踪框架，需要通过文件系统接口提供控制和输出功能。ftrace实际上使用tracefs文件系统，但为了向后兼容，也可以挂载在debugfs下。如果不挂载相应的文件系统，就无法访问ftrace的控制和输出文件，无法使用ftrace功能。\n\n1. ftrace的文件系统依赖：\n   - tracefs文件系统：\n     * ftrace实际上使用tracefs文件系统（不是debugfs）\n     * tracefs是专门为内核跟踪设计的文件系统\n",
            "Trace工具-ftrace"

        self.add_card(
            "如何通过perfetto UI分析trace文件？",",
            "1. CPU调度情况：查看进程和线程的执行时间线\n2. 进程和线程：查看执行时间线、调度延迟等\n3. 系统调用和函数调用栈：定位性能瓶颈\n4. 锁竞争和等待时间：识别锁竞争问题\n5. 内存分配和释放：分析内存使用情况\n6. 结合系统日志：定位CPU高负载的根本原因",
            "Trace工具-perfetto"
        )

        self.add_card(",
            "如何触发抓取trace？",
            "Trace工具-抓取",
            "Trace工具-抓取"
        )

        self.add_card(",
            "trace分析中如何定位CPU高负载问题？",
            "Trace工具-分析",
            "Trace工具-分析"
        )

        self.add_card(",
            "perfetto trace文件包含哪些数据源？",
            "Trace工具-perfetto",
            "Trace工具-perfetto"
        )

        self.add_card(",
            "如何在perfetto中分析锁竞争问题？",
            "Trace工具-锁分析",
            "Trace工具-锁分析"
        )

        self.add_card(",
            "systrace中的关键指标有哪些？",
            "Trace工具-指标",
            "Trace工具-指标"
        )

        self.add_card(",
            "如何通过trace分析应用启动时间？",
            "Trace工具-启动分析",
            "Trace工具-启动分析"
        )

    def generate_pmic_gauge_cards(self):
        ""生成PMIC/Gauge相关的卡片""

        self.add_card(",
            "Battery Gauge（电池电量计）的作用是什么？",
            "PMIC/Gauge-基础",
            "PMIC/Gauge-基础"
        )

        self.add_card(",
            "如何评估Gauge的功耗损耗？",
            "PMIC/Gauge-优化",
            "PMIC/Gauge-优化"
        )

        self.add_card(",
            "如何从PMIC获取功耗数据？",
            "PMIC数据获取的完整流程和方法：\n\n1. 硬件通信方式：\n   - I2C总线：最常用的通信方式，通过I2C协议访问PMIC寄存器\n",
            "PMIC/Gauge-数据获取"

        self.add_card(
            "如何区分PMIC的数据和Gauge的数据？",",
            "在实际应用中，可以通过多个维度区分PMIC数据和Gauge数据：\n\n1. 数据源识别：\n   - PMIC数据来源：\n     * 通过I2C/SPI/SPMI总线访问PMIC寄存器\n     * 寄存器地址通常在PMIC规格书中定义（如0x0B为电池电压寄存器）\n     * 通过/sys/class/power_supply/battery/路径下的节点读取（Kernel层暴露）\n"
            "PMIC/Gauge-对比",
            "PMIC/Gauge-对比"

        self.add_card(",
            "什么是库仑计（Coulomb Counter）？",
            "PMIC/Gauge-库仑计",
            "PMIC/Gauge-库仑计"
        )

        self.add_card(",
            "PMIC中的LDO和BUCK有什么区别？",
            "PMIC/Gauge-电源管理",
            "PMIC/Gauge-电源管理"
        )

        self.add_card(",
            "什么是电池健康度（Battery Health）？如何评估？",
            "PMIC/Gauge-电池健康",
            "PMIC/Gauge-电池健康"
        )

        self.add_card(",
            "PMIC如何实现动态电压调节（DVS）？",
            "PMIC/Gauge-DVS",
            "PMIC/Gauge-DVS"
        )

        # 豆包对话：PMIC核心概念
        self.add_card(",
            "PMIC（电源管理芯片）的核心作用是什么？",
            "PMIC/Gauge-核心概念",
            "PMIC/Gauge-核心概念"
        )

        self.add_card(",
            "DVS（动态电压调节）的工作原理是什么？",
            "PMIC/Gauge-核心概念",
            "PMIC/Gauge-核心概念"
        )

        self.add_card(",
            "DVS的核心优势有哪些？",
            "PMIC/Gauge-核心概念",
            "PMIC/Gauge-核心概念"
        )

        self.add_card(",
            "DVS的常见应用场景有哪些？",
            "PMIC/Gauge-核心概念",
            "PMIC/Gauge-核心概念"
        )

        # 豆包对话：PMIC与内存的关系
        self.add_card(",
            "为什么内存需要独立的PMIC供电？",
            "PMIC/Gauge-内存关系",
            "PMIC/Gauge-内存关系"
        )

        self.add_card(",
            "为什么PMIC不是SoC的一部分？",
            "PMIC/Gauge-内存关系",
            "PMIC/Gauge-内存关系"
        )

        # 豆包对话：手机中多颗PMIC的原因
        self.add_card(",
            "手机中为什么需要2~3颗PMIC？主要原因是什么？",
            "PMIC/Gauge-多PMIC",
            "PMIC/Gauge-多PMIC"
        )

        self.add_card(",
            "不同定位手机的PMIC数量有什么区别？",
            "PMIC/Gauge-多PMIC",
            "PMIC/Gauge-多PMIC"
        )

        # 豆包对话：PMIC读取数据的能力
        self.add_card(",
            "PMIC如何读取电压？",
            "PMIC/Gauge-数据读取",
            "PMIC/Gauge-数据读取"
        )

        self.add_card(",
            "PMIC如何读取电流？两种方法有什么区别？",
            "PMIC/Gauge-数据读取",
            "PMIC/Gauge-数据读取"
        )

        self.add_card(",
            "PMIC读取电压/电流的核心目的有哪些？",
            "PMIC/Gauge-数据读取",
            "PMIC/Gauge-数据读取"
        )

        self.add_card(",
            "不同层级如何读取PMIC数据？"加工后数据\"，通过sysfs节点或HAL接口获取（需要root/系统权限）\n3. APP层：只能读取系统开放的\"极简数据\"，通过BatteryManager等系统API获取电池电压、剩余电量、充电状态等",",
            "PMIC/Gauge-数据读取"
        )

        self.add_card(
            "不同层级读取PMIC数据的具体代码示例是什么？",",
            "不同层级读取PMIC数据的具体代码示例：\n1. Kernel层（伪代码，驱动层面）：通过I2C总线直接读取PMIC寄存器（如0x0B为电池电压寄存器地址），使用i2c_smbus_read_word_data()函数直接读PMIC寄存器\n2. Native层（C++示例）：读取sysfs节点（如/sys/class/power_supply/battery/current_now），需要root权限，读取后转换为毫安单位\n3. APP层（Java示例）：通过BatteryManager API获取电池电压和充电状态，使用IntentFilter和Intent.ACTION_BATTERY_CHANGED",
            "PMIC/Gauge-数据读取"
        )

        # 豆包对话：PMIC数据包括什么
        self.add_card(",
            "PMIC数据的完整分类有哪些？",
            "PMIC/Gauge-数据分类",
            "PMIC/Gauge-数据分类"
        )

        self.add_card(",
            "PMIC能否读取SoC内外器件的电流电压？",
            "PMIC/Gauge-数据分类",
            "PMIC/Gauge-数据分类"
        )

        # 豆包对话：MOS管
        self.add_card(",
            "MOS管的核心作用是什么？",
            "PMIC/Gauge-MOS管",
            "PMIC/Gauge-MOS管"
        )

        self.add_card(",
            "MOS管的工作原理是什么？"3个电极+1层绝缘膜\"：\n- 源极（Source，S）：提供电流的\"源头\"\n- 漏极（Drain，D）：电流流出的\"出口\"\n- 栅极（Gate，G）：控制电流通断的\"开关手柄\"\n\n核心工作逻辑（以N沟道MOS管为例）：\n- 栅极不加电压：源极和漏极之间的半导体通道是\"断开\"的，电流无法通过 → MOS管关断\n- 栅极加正向电压：电压会穿过绝缘膜，在半导体表面感应出大量电子，形成一条导电通道 → 源极和漏极导通，电流可以从D流向S → MOS管打开\n- 电压越大，通道越宽：栅极电压越高，导电通道的电阻越小，流过的电流就越大\n\n关键特点：栅极和其他电极之间是绝缘的，几乎没有电流流过，因此MOS管的控制功耗极低。",",
            "PMIC/Gauge-MOS管"
        )

        self.add_card(
            "MOS管在PMIC中的核心作用是什么？",
            "1. DC-DC降压转换器：PMIC的DC-DC模块需要将高压转换成低压，这个过程依赖\"开关电源拓扑\"（如BUCK电路），而MOS管就是拓扑中的核心开关。两颗MOS管交替导通/关断，通过调节开关频率和占空比，精准控制输出电压\n2. LDO稳压电路：LDO需要提供无纹波的精准电压，MOS管在这里充当可调限流元件。栅极电压由反馈电路控制，当输出电压偏高时，栅极电压降低，MOS管电阻变大，电流减小，输出电压回落；反之亦然",",
            "PMIC/Gauge-MOS管"
        )

        self.add_card(
            "MOS管的关键优势有哪些？",",
            "1. 功耗极低：栅极绝缘，控制电流几乎为0\n2. 开关速度快：导通/关断时间可以达到纳秒级\n3. 集成度高：体积小，可以被集成到芯片内部\n4. 耐高温、抗干扰：适合手机内部高温、高电磁干扰的环境",
            "PMIC/Gauge-MOS管"
        )

        self.add_card(",
            "MOS管和三极管的区别是什么？",
            "PMIC/Gauge-MOS管",
            "PMIC/Gauge-MOS管"
        )

    def generate_kernel_scheduler_cards(self):
        ""生成Kernel调度相关的卡片""

        self.add_card(",
            "Linux内核调度器的主要目标是什么？",
            "Kernel调度-基础",
            "Kernel调度-基础"
        )

        self.add_card(",
            "什么是调度延迟（Scheduling Latency）？",
            "Kernel调度-性能",
            "Kernel调度-性能"
        )

        self.add_card(",
            "进程的睡眠状态有哪些？",
            "Kernel调度-进程状态",
            "Kernel调度-进程状态"
        )

        self.add_card(",
            "什么是CPU亲和性（CPU Affinity）？",
            "Kernel调度-亲和性",
            "Kernel调度-亲和性"
        )

        self.add_card(",
            "什么是NUMA（Non-Uniform Memory Access）？",
            "Kernel调度-NUMA",
            "Kernel调度-NUMA"
        )

        self.add_card(",
            "CFS（完全公平调度器）的工作原理是什么？",
            "Kernel调度-CFS",
            "Kernel调度-CFS"
        )

        self.add_card(",
            "vruntime（虚拟运行时间）的计算方式是什么？"虚拟\"执行时间\n   - 作用：用于在红黑树中排序任务，总是选择vruntime最小的任务执行\n",",
            "Kernel调度-CFS"
        )

        self.add_card(
            "进程的nice值如何影响调度？",",
            "1. nice值范围：-20到19，值越小优先级越高\n2. 权重计算：nice值影响进程的权重，权重越大获得的时间片越多\n3. 默认值：普通进程的nice值为0\n4. 实时进程：实时进程（RT调度类）的优先级高于普通进程\n5. 调整方式：可以通过nice()或setpriority()系统调用调整",
            "Kernel调度-优先级"
        )

        self.add_card(",
            "上下文切换（Context Switch）的开销有哪些？",
            "Kernel调度-上下文切换",
            "Kernel调度-上下文切换"
        )

        self.add_card(",
            "负载均衡（Load Balancing）在多核系统中的作用是什么？",
            "Kernel调度-负载均衡",
            "Kernel调度-负载均衡"
        )

        self.add_card(",
            "每个CPU核心的runqueue（rq）和调度器在核心间的负载均衡是什么？",
            "Linux内核调度器采用每个CPU核心一个runqueue（rq）的设计，调度器既维护每个rq，也负责在核心间进行负载均衡和任务迁移。\n\n1. 每个核心的runqueue（rq）：\n   - 定义：\n     * 每个CPU核心都有一个独立的runqueue（rq），存储分配给该核心的所有可运行任务\n     * rq是调度器的核心数据结构，包含该核心的任务队列、负载信息、调度统计等\n",
            "Kernel调度-负载均衡"

        self.add_card(
            "实时调度类（RT调度类）的特点是什么？",",
            "1. 优先级：实时进程的优先级高于普通进程（CFS）\n2. 调度策略：\n   - SCHED_FIFO：先进先出，相同优先级按FIFO顺序\n   - SCHED_RR：轮询调度，相同优先级按时间片轮询\n3. 抢占：实时进程可以抢占普通进程\n4. 时间片：SCHED_RR有时间片限制，SCHED_FIFO没有\n5. 适用场景：对实时性要求高的任务（如音频、视频处理）",
            "Kernel调度-实时调度"
        )

        self.add_card(",
            "Linux调度类的完整对比和层级关系是什么？（Stop、Deadline、RT、CFS、IDLE）",
            "Linux内核的调度器采用分层设计，包含多个调度类（Scheduler Class），每个调度类有不同的调度策略（Policy），形成完整的调度层级结构。\n\n1. 调度类的层级结构（优先级从高到低）：\n   - Stop Class（停止调度类）：\n     * 优先级：最高（最高优先级）\n     * 用途：处理关键系统操作（如CPU热插拔、任务迁移）\n     * 策略：无用户可配置策略，内核内部使用\n",
            "Kernel调度-实时调度"

        self.add_card(
            "RT调度（SCHED_FIFO和SCHED_RR）和Deadline调度（SCHED_DEADLINE）的对比是什么？",
            "RT调度（SCHED_FIFO、SCHED_RR）和Deadline调度（SCHED_DEADLINE）是Linux内核中两种不同的实时调度策略，分别基于优先级和截止时间进行调度，各有特点和适用场景（详细系统性介绍参见\"Linux调度类的完整对比和层级关系\"）。\n\n1. 核心概念对比：\n   - RT调度（Priority-Based Scheduling）：\n     * 调度依据：静态优先级（1-99，数字越大优先级越高）\n     * 策略类型：SCHED_FIFO（先进先出）和SCHED_RR（轮询调度）\n",
            "Kernel调度-实时调度"

        self.add_card(
            "进程组（Process Group）和会话（Session）在调度中的作用？",",
            "1. 进程组：相关进程的集合，可以一起接收信号\n2. 会话：进程组的集合，通常对应一个终端\n3. 调度影响：\n   - 进程组内的进程可以共享CPU时间\n   - 会话可以作为一个整体进行调度\n4. 控制终端：前台进程组可以接收终端输入\n5. 信号传递：可以向进程组或会话发送信号",
            "Kernel调度-进程组织"
        )

    def generate_power_supply_cards(self):
        ""生成Power Supply相关的卡片""

        self.add_card(",
            "什么是Power Supply子系统？",
            "Power Supply-基础",
            "Power Supply-基础"
        )

        self.add_card(",
            "Power Supply子系统中的属性有哪些？",
            "Power Supply-属性",
            "Power Supply-属性"
        )

        self.add_card(",
            "如何通过Power Supply子系统获取电池信息？",
            "Power Supply-数据获取",
            "Power Supply-数据获取"
        )

        self.add_card(",
            "Power Supply驱动如何实现？",
            "Power Supply-驱动实现",
            "Power Supply-驱动实现"
        )

        self.add_card(",
            "Power Supply子系统中的uevent机制是什么？Power Supply发送uevent，是不是userspace有监听才能收到，或者说注册回调？给出完整过程。",
            "是的，Power Supply发送uevent后，userspace必须主动监听netlink socket才能收到事件。这不是注册回调机制，而是基于netlink socket的事件监听机制。完整过程包括内核发送uevent、通过netlink传输、userspace监听接收三个步骤。\n\n1. 核心概念：\n   - uevent机制：\n     * uevent是Linux内核向用户空间发送设备事件通知的机制\n     * 用于通知设备添加、删除、状态变化等事件\n",
            "Power Supply-uevent"

        self.add_card(
            "Power Supply子系统中的充电状态有哪些？",",
            "充电状态（status属性）包括：\n1. Unknown：未知状态\n2. Charging：正在充电\n3. Discharging：正在放电\n4. Not charging：未充电（可能已满或温度异常）\n5. Full：已充满\n状态转换：\n- 插入充电器：Discharging -> Charging\n- 充满：Charging -> Full\n- 拔出充电器：Charging/Full -> Discharging\n- 温度异常：可能变为Not charging\n应用：系统根据充电状态调整功耗策略，如充电时可以提高性能，放电时降低功耗。",
            "Power Supply-充电状态"
        )

        self.add_card(",
            "如何通过Power Supply子系统监控功耗？",
            "Power Supply-功耗监控",
            "Power Supply-功耗监控"
        )

        # 豆包对话：电池管理
        self.add_card(",
            "PMU和PMIC的区别是什么？",
            "Power Supply-PMU/PMIC",
            "Power Supply-PMU/PMIC"
        )

        self.add_card(",
            "如何获取电池消耗量？三种方式有什么区别？",
            "Power Supply-电池消耗",
            "Power Supply-电池消耗"
        )

        self.add_card(",
            "Gauge和库仑计的关系是什么？"库仑\"这个电量单位的定义，来直接计算出到底用了多少电或者充进去多少电\n3. 它们能获取的数据：主要就是电池的剩余电量、已用电量、充电速度、放电速度这些\n4. 相比其他类型的电量计，比如通过测电池电压来估算电量的那种，库仑计因为是直接计量电流，所以结果会准确得多，尤其是在电池使用时间比较长、老化之后，电压法会越来越不准，库仑计的优势就更明显了",",
            "Power Supply-Gauge/库仑计"
        )

        self.add_card(
            "PMIC和Fuel Gauge在实际应用中的协作关系是什么？",
            "PMIC和Fuel Gauge不是竞争关系，而是\"协同工作\"的关系：\n\n充电阶段：\n1. PMIC负责与充电器协商快充协议，实时采样电池电压/电流，调整充电档位\n2. Fuel Gauge实时计算SoC，当SoC达到100%时，通知PMIC停止快充，切换到涓流充电\n3. 若PMIC检测到过压/过流，立即切断充电，同时Fuel Gauge记录此次异常事件\n\n放电阶段：\n1. PMIC负责给系统供电，实时监测放电电流，防止过流/欠压\n2. Fuel Gauge通过积分计算剩余容量，结合当前放电电流预测续航时间，显示在手机状态栏\n3. 当电池电压低于3.0V时，PMIC触发关机，Fuel Gauge记录关机前的SoC和电压",",
            "Power Supply-PMIC/FuelGauge"
        )

        self.add_card(
            "Modem、WiFi、蓝牙、基带的关系是什么？",
            "Modem（调制解调器）：\n- 作用：主要负责通过蜂窝网络联网，也就是我们说的移动数据，像4G、5G这些，让手机能在没有Wi-Fi的地方上网、打电话、发短信\n- 位置：现在很多中高端手机，Modem会和CPU、GPU这些核心一起，直接集成在SOC芯片里面。但有些低端手机或者早期的手机，为了降低成本，会采用分离式设计，这时候Modem就是一个独立的芯片\n\nWiFi和蓝牙：\n- WiFi作用：负责连接无线路由器，在有Wi-Fi覆盖的地方，比如家里、公司，用它上网速度更快，也更省电量，不会消耗手机的流量\n- 蓝牙作用：主要用于短距离通信，比如连接耳机、手环、车载系统这些，传输的数据量比较小，距离也近，一般在10米左右\n- 硬件集成：现在很多手机会把Wi-Fi和蓝牙集成到一个芯片里，叫Combo芯片，而Modem可能是集成在SOC里，也可能是独立的\n- 协调工作：它们之间会通过SOC内部的总线或者外部接口来协调工作，比如手机会优先选择Wi-Fi上网，这时Modem就会进入低功耗状态，只负责接收电话和短信，这样能节省电量\n\n基带（Baseband）：\n- 作用：手机里的基带，你可以理解成\"通信大脑\"，它主要负责处理所有和蜂窝网络相关的通信任务。比如说，你用移动数据上网、打电话、发短信，这些信号的编码解码、调制解调，还有和基站之间的信号交互，都是基带在管\n- 与Modem的关系：Modem是基带的核心硬件部分。基带是一个更完整的系统，它除了包含Modem芯片，还包括负责信号处理的数字信号处理器，以及存储通信协议和算法的固件。所以可以说，Modem是基带的\"心脏\"，而基带则是整个手机通信功能的基础\n- 与WiFi/蓝牙的关系：基带主要负责的就是蜂窝网络，像4G、5G这些。蓝牙和WiFi有专门的芯片来处理，它们仨就像是三个不同的通信通道，各自管一块，这样分工明确，效率也更高",",
            "Power Supply-通信模块"
        )

    def generate_os_basics_cards(self):
        ""生成操作系统基础相关的卡片""

        # 信号量
        self.add_card(",
            "信号量（Semaphore）的核心作用是什么？"许可证\"：当进程/线程要访问共享资源时，需要先获取信号量，若信号量计数大于0则计数减1，否则阻塞等待；当进程/线程用完资源后，会释放信号量，让计数加1，唤醒等待的执行单元。",",
            "操作系统基础-信号量"
        )

        self.add_card(
            "POSIX信号量和System V信号量的区别是什么？",",
            "POSIX信号量：\n- 支持线程间和进程间同步\n- 接口简单（sem_init / sem_wait / sem_post）\n- 分为有名信号量（跨进程）和无名信号量（线程间）\n\nSystem V信号量：\n- 以信号量集的形式存在\n- 接口相对复杂（semget / semop / semctl）\n- 可同时管理多个信号量，适用于更复杂的进程间同步场景",
            "操作系统基础-信号量"
        )

        self.add_card(",
            "信号量的应用场景有哪些？",
            "操作系统基础-信号量",
            "操作系统基础-信号量"
        )

        self.add_card(",
            "信号量计数器可以小于0吗？",
            "操作系统基础-信号量",
            "操作系统基础-信号量"
        )

        self.add_card(",
            "信号量和读写锁的区别是什么？"通行证\"，不会区分\"读\"和\"写\"，适合控制资源访问数量\n\n读写锁：专门为\"多读少写\"场景设计，能让读操作并发执行，提高效率。多个线程可以同时读（因为读不会改数据，不冲突）；但只要有一个线程在写，所有读线程和其他写线程都得等",",
            "操作系统基础-信号量"
        )

        self.add_card(
            "读写锁的工作原理是什么？",",
            "读写锁的工作原理\n"
            "操作系统基础-信号量"
        )

        self.add_card(",
            "为什么信号量被称为进程间通信手段？"资源可用\"的信号，这其实就是一种间接的信息交换。虽然它不像Socket那样直接传递数据，但它解决了进程间\"什么时候该做什么\"的协同问题，这对于多进程协作来说至关重要。",",
            "操作系统基础-信号量"
        )

        self.add_card(
            "锁和信号量在设计初衷和适用场景上的区别是什么？",
            "锁和信号量在设计初衷和适用场景上的区别：\n1. 设计初衷：\n   - 锁的主要作用是互斥，防止多个进程同时操作共享资源，更侧重于\"保护资源\"\n   - 信号量实现进程间的同步信号传递，这是进程通信的重要组成部分，更侧重于\"传递信号\"\n2. 适用场景：\n   - 锁：用于保护共享资源，防止多个进程同时写入造成数据混乱（如保护共享的历史数据库）\n   - 信号量：可以用来控制同时进行任务的进程数量（如只想让3个进程同时跑，避免过度占用服务器资源）\n3. 形象",
            "操作系统基础-信号量"
        )

        self.add_card(
            "POSIX信号量的具体使用细节有哪些？",",
            "POSIX信号量的具体使用细节：\n1. sem_init()初始化信号量：\n   - 第二个参数：0表示信号量用于同一进程的线程间共享；若为非0则用于进程间共享\n   - 第三个参数：信号量的初始计数值\n2. sem_wait()：阻塞式申请信号量，计数>0则减1，否则阻塞等待\n3. sem_trywait()：非阻塞版本，失败直接返回错误，不会阻塞\n4. sem_post()：释放信号量，计数加1，唤醒等待的线程\n5. 信号量初始值的作用：\n   - 初始值为1时，等价于互斥锁（一次只允许一个线程访问）\n   - 初始值大于1时，可实现多线程并发访问（如同时允许3个线程进入临界区）",
            "操作系统基础-信号量"
        )

        # JNI
        self.add_card(",
            "JNI（Java Native Interface）的核心作用是什么？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "JNI的具体用途有哪些？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "JNI是跨进程调用吗？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "JNI中为什么会出现内存泄漏？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "应用层如何与Native进程通信？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "Native进程之间的通信方式有哪些？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "单纯使用JNI的场景是什么？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "Java进程和C++进程在不同进程时，如何实现协作和通信？",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        self.add_card(",
            "Native层使用Binder和Socket的区别是什么？包括效率、适用场景和安全性方面的区别",
            "操作系统基础-JNI",
            "操作系统基础-JNI"
        )

        # 内存管理
        self.add_card(",
            "mmap（内存映射）的作用是什么？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "用户态进程访问内核映射的文件节点时，权限和效率问题如何解决？"应用层→JNI→守护进程→节点\"的路线",",
            "操作系统基础-内存管理"
        )

        self.add_card(
            "是否能由Native进程进行mmap，映射到APK层地址空间？",",
            "Native进程无法直接将mmap映射到APK层（Java层）的地址空间，因为进程地址空间是隔离的，但可以通过共享内存等方式实现数据共享。\n\n1. 核心问题：\n   - 进程地址空间隔离：\n     * Native进程和APK进程（Android应用进程）是不同的进程\n     * 每个进程有独立的虚拟地址空间，无法直接跨进程映射\n"
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"

        self.add_card(",
            "APK层是否能通过Binder与Native层进程通信，再由Native层读取系统节点，从而实现APK层读取节点的功能？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "mmap分配连续内存时，内存泄漏、越界访问、多进程共享的问题如何解决？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "Binder通信的核心优势是什么？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "Binder通信单次传输的数据大小限制是多少？为什么有这个限制？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "Android Ashmem（匿名共享内存）的原理和用途是什么？",
            "Ashmem（Anonymous Shared Memory，匿名共享内存）是Android特有的共享内存机制，用于实现高效的进程间数据共享，是Android系统进程间通信的重要基础设施。\n\n1. 核心概念：\n   - 定义：Ashmem是Android内核驱动提供的匿名共享内存机制，允许不同进程共享同一块物理内存\n   - 特点：\n     * 匿名：不需要文件系统支持，不需要创建文件\n     * 共享：多个进程可以映射同一块共享内存\n     * 高效：直接共享物理页面，避免数据拷贝\n",
            "操作系统基础-内存管理"

        self.add_card(
            "Binder通信如何实现一次拷贝？",",
            "Binder通信通过mmap创建的共享内存缓冲区实现一次拷贝，发送方直接将数据写入共享内存，接收方直接从共享内存读取，避免了传统IPC（如Socket）的多次拷贝开销。\n\n1. 核心机制：共享内存缓冲区\n   - mmap创建共享内存：\n     * Binder驱动在初始化时，为每个进程通过mmap分配一块共享内存缓冲区（通常1MB）\n     * 这块共享内存被映射到所有参与Binder通信的进程的虚拟地址空间\n     * 多个进程的虚拟地址映射到同一块物理内存\n"
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"

        self.add_card(",
            "异步回栈的内存消耗主要包含哪些部分？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "主流语言/框架如何统计异步回栈内存占用？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        # Linux Write Back相关
        self.add_card(",
            "缓存写策略有哪两种？各有什么特点？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "Write Back和Write Through有什么区别？如何选择？"缓存写策略有哪两种？各有什么特点？\"）。\n\n1. 性能对比：\n   - Write Through：\n     * 写入延迟：高（需要等待底层存储写入完成）\n     * 写入吞吐量：低（每次写入都要访问底层存储）\n",
            "操作系统基础-内存管理"

        self.add_card(
            "脏页（Dirty Page）的详细概念是什么？",",
            "脏页（Dirty Page）是页缓存中被修改但尚未写回磁盘的页面，是Write Back机制的核心概念。\n\n1. 定义和产生：\n   - 定义：页缓存中被修改但尚未写回磁盘的页面\n   - 产生过程：\n     * 进程写入文件时，数据先写入页缓存\n     * 页缓存中的数据与磁盘上的数据不一致\n     * 该页面被标记为脏页（dirty page）\n",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "内核缓冲区（Kernel Buffer）是什么？",
            "内核缓冲区是操作系统内核用于缓存I/O数据的内存区域，是内核I/O子系统的重要组成部分，用于提高I/O性能和减少系统调用开销。\n\n1. 核心概念：\n   - 定义：内核缓冲区是内核维护的内存区域，用于缓存用户态和内核态之间的I/O数据\n   - 作用：\n     * 减少用户态和内核态之间的数据拷贝次数\n     * 提高I/O性能，减少对慢速设备的直接访问\n     * 实现批量I/O操作，提高效率\n",
            "操作系统基础-内存管理"

        self.add_card(
            "Linux页缓存（Page Cache）是什么？",",
            "Linux页缓存是内核用于缓存文件数据的内存区域。\n\n核心概念：\n1. 作用：将文件数据缓存在内存中，减少磁盘I/O操作，提高文件读写性能\n",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "Linux Write Back（回写）机制的工作原理是什么？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "Linux Write Back机制中的关键参数有哪些？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "pdflush和现代flusher线程的区别是什么？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "fsync、sync、fdatasync的区别是什么？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "Write Back机制可能导致哪些问题？如何解决？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "为什么Linux选择Write Back而不是Write Through？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "libuv中如何统计异步回调内存占用？",
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"
        )

        # ELF文件格式
        self.add_card(",
            "ELF（Executable and Linkable Format）文件格式是什么？",
            "操作系统基础-文件格式",
            "操作系统基础-文件格式"
        )

        self.add_card(",
            "ELF文件中的Segment和Section有什么区别？",
            "操作系统基础-文件格式",
            "操作系统基础-文件格式"
        )

        # 中断
        self.add_card(",
            "中断（Interrupt）有哪几种类型？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "硬件中断（Hardware Interrupt）的用途和机制是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "定时器中断（Timer Interrupt）的用途和机制是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "软件中断（Software Interrupt）的用途和机制是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "异常（Exception）的用途和机制是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "ARM架构中的GIC（Generic Interrupt Controller）是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "ARM架构中的IRQ和FIQ有什么区别？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "中断处理流程是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "Physical SError Interrupt（系统错误中断）是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        # MMU中断/异常
        self.add_card(",
            "MMU中断（内存管理单元异常）有哪些类型？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "缺页异常（Page Fault）的详细机制是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "TLB Miss的处理机制是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "MMU访问权限错误的类型和处理是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "BUS Error（总线错误）是什么？",
            "操作系统基础-中断",
            "操作系统基础-中断"
        )

        self.add_card(",
            "如何调试MMU相关错误？"Segmentation fault\"\n\n2. 总线错误（Bus Error，SIGBUS）：\n   - 原因：对齐错误、访问无效地址\n   - 表现：程序崩溃，输出\"Bus error\"\n\n3. 权限错误：\n   - 原因：访问权限不足（用户态访问内核内存、写入只读内存、执行数据段）\n   - 表现：程序崩溃或权限拒绝\n\n4. 缺页异常过多：\n   - 原因：内存不足、内存泄漏、频繁swap\n   - 表现：系统性能下降、响应变慢\n\n调试工具和方法：\n1. GDB（GNU Debugger）：\n   - 功能：断点调试、内存检查、堆栈跟踪\n   - 使用方法：\n     * gdb ./program：启动GDB调试程序\n     * run：运行程序\n     * bt：查看堆栈跟踪（backtrace）\n     * info registers：查看寄存器状态\n     * x/10x $sp：查看栈内存\n     * print *ptr：查看指针指向的内容\n",",
            "操作系统基础-中断"
        )

        self.add_card(
            "如何使用maps、smaps和符号表调试MMU相关错误？",
            "使用/proc/PID/maps、/proc/PID/smaps和符号表是调试MMU相关错误的重要方法。\n\n1. /proc/PID/maps的使用：\n   - 功能：查看进程的内存映射布局\n   - 使用方法：\n     * cat /proc/PID/maps：查看进程的所有内存映射\n     * grep \"heap\" /proc/PID/maps：查找堆区域\n     * grep \"stack\" /proc/PID/maps：查找栈区域\n   - 输出格式：\n     * 地址范围 权限 偏移 设备 inode 路径\n     * 例如：00400000-00401000 r-xp 00000000 08:01 123456 /path/to/program\n   - 信息内容：\n     * 虚拟地址范围：每个内存区域的起始和结束地址\n     * 权限：r（读）、w（写）、x（执行）、p（私有）或s（共享）\n     * 映射的文件：代码段、数据段、共享库等\n",",
            "操作系统基础-内存管理"
        )

        self.add_card(
            "maps和smaps有什么区别？",",
            "/proc/PID/maps和/proc/PID/smaps都是查看进程内存映射的工具，但提供的信息详细程度不同。\n\n1. /proc/PID/maps：\n   - 功能：查看进程的内存映射布局（概览）\n   - 输出格式：\n     * 地址范围 权限 偏移 设备 inode 路径\n     * 例如：00400000-00401000 r-xp 00000000 08:01 123456 /path/to/program\n   - 信息内容：\n     * 虚拟地址范围：每个内存区域的起始和结束地址\n     * 权限：r（读）、w（写）、x（执行）、p（私有）或s（共享）\n     * 偏移：文件中的偏移量\n     * 设备：设备号（主设备号:次设备号）\n     * inode：文件inode号\n     * 路径：映射的文件路径（如果有）\n   - 特点：\n     * 信息简洁，一行一个内存区域\n     * 快速查看内存布局\n     * 文件大小较小\n",
            "操作系统基础-内存管理"
        )

        self.add_card(",
            "段错误（Segmentation Fault）的详细机制是什么？",
            "段错误（Segmentation Fault，SIGSEGV）是访问无效内存段时MMU检测到的异常，是内存保护的核心机制之一。\n\n1. 核心概念：\n   - 定义：\n     * 段错误是访问无效虚拟地址时MMU触发的异常\n     * Linux/Unix系统中，段错误对应SIGSEGV信号\n",
            "操作系统基础-中断"

        self.add_card(
            "对齐错误（Alignment Fault）的详细机制是什么？",",
            "对齐错误（Alignment Fault）是访问未对齐的内存地址时MMU或硬件检测到的异常，某些架构要求内存访问必须对齐。\n\n1. 核心概念：\n   - 定义：\n     * 对齐错误是访问未对齐的内存地址时触发的异常\n     * 某些架构（如ARM、SPARC）要求内存访问必须对齐到特定边界\n"
            "操作系统基础-中断",
            "操作系统基础-中断"

        self.add_card(",
            "Linux驱动开发到挂载的完整流程是什么？",
            "操作系统基础-驱动开发",
            "操作系统基础-驱动开发"
        )

        self.add_card(",
            "驱动开发以及注册到系统的流程是什么？",
            "Linux驱动开发是内核编程的重要组成部分，驱动注册到系统是驱动工作的关键步骤。\n\n1. 驱动开发的基本概念：\n   - 驱动的定义：\n     * 驱动是内核模块，用于控制和管理硬件设备\n     * 驱动提供统一的接口，让应用程序可以访问硬件\n",
            "操作系统基础-驱动开发"

        self.add_card(
            "如何区分MMU和IOMMU？",",
            "MMU（Memory Management Unit）和IOMMU（Input-Output Memory Management Unit）都是内存管理单元，但服务于不同的对象和应用场景。\n\n1. 服务对象区分：\n   - MMU：\n     * 服务对象：CPU（中央处理器）\n     * 处理对象：CPU指令访问的内存（指令取指、数据读写）\n"
            "操作系统基础-内存管理",
            "操作系统基础-内存管理"

    def generate_bus_technology_cards(self):
        ""生成总线技术相关的卡片""

        # 总线的核心定义与经典理论
        self.add_card(",
            "总线的核心定义是什么？",
            "总线技术-基础理论",
            "总线技术-基础理论"
        )

        self.add_card(",
            "冯·诺依曼总线架构的特点是什么？",
            "总线技术-基础理论",
            "总线技术-基础理论"
        )

        self.add_card(",
            "三总线结构包括哪些？各有什么特点？",
            "总线技术-基础理论",
            "总线技术-基础理论"
        )

        self.add_card(",
            "总线仲裁（解决争用）有哪些方式？",
            "总线技术-基础理论",
            "总线技术-基础理论"
        )

        self.add_card(",
            "总线时序（同步/异步）的区别是什么？",
            "总线技术-基础理论",
            "总线技术-基础理论"
        )

        self.add_card(",
            "总线带宽的计算公式是什么？",
            "总线技术-基础理论",
            "总线技术-基础理论"
        )

        self.add_card(",
            "总线的带宽是什么？如何计算和测量？",
            "总线技术-性能指标",
            "总线技术-性能指标"
        )

        self.add_card(",
            "总线的延迟是什么？如何测量？",
            "总线技术-性能指标",
            "总线技术-性能指标"
        )

        self.add_card(",
            "总线的吞吐量和效率是什么？如何计算？",
            "总线技术-性能指标",
            "总线技术-性能指标"
        )

        self.add_card(",
            "总线的并发能力和可扩展性是什么？",
            "总线技术-性能指标",
            "总线技术-性能指标"
        )

        self.add_card(",
            "总线的可靠性和功耗如何衡量？",
            "总线技术-性能指标",
            "总线技术-性能指标"
        )

        self.add_card(",
            "如何测试总线的性能？",
            "总线技术-性能指标",
            "总线技术-性能指标"
        )

        self.add_card(",
            "不同总线的性能对比是什么？",
            "总线技术-对比",
            "总线技术-对比"
        )

        # 总线的核心分类
        self.add_card(",
            "总线的核心分类有哪些？",
            "总线技术-分类",
            "总线技术-分类"
        )

        # 双工模式
        self.add_card(",
            "全双工、半双工、单工的区别是什么？",
            "总线技术-双工模式",
            "总线技术-双工模式"
        )

        self.add_card(",
            "双工模式的补充与实战提示是什么？",
            "总线技术-双工模式",
            "总线技术-双工模式"
        )

        # 常用总线技术详解
        self.add_card(",
            "I2C总线的完整特点是什么？",
            "总线技术-I2C",
            "总线技术-I2C"
        )

        self.add_card(",
            "SPI总线的完整特点是什么？",
            "总线技术-SPI",
            "总线技术-SPI"
        )

        self.add_card(",
            "UART/RS-232总线的完整特点是什么？",
            "总线技术-UART",
            "总线技术-UART"
        )

        self.add_card(",
            "RS-485总线的完整特点是什么？",
            "总线技术-RS-485",
            "总线技术-RS-485"
        )

        self.add_card(",
            "PCIe总线的完整特点是什么？",
            "总线技术-PCIe",
            "总线技术-PCIe"
        )

        self.add_card(",
            "I2C和PCIe有什么区别？如何选择？",
            "总线技术-对比",
            "总线技术-对比"
        )

        self.add_card(",
            "USB总线的完整特点是什么？",
            "总线技术-USB",
            "总线技术-USB"
        )

        self.add_card(",
            "MIPI总线的完整特点是什么？",
            "总线技术-MIPI",
            "总线技术-MIPI"
        )

        self.add_card(",
            "CXL总线的完整特点是什么？",
            "总线技术-CXL",
            "总线技术-CXL"
        )

        # 最新总线技术与发展趋势
        self.add_card(",
            "PCIe 6.0的核心升级是什么？",
            "总线技术-最新技术",
            "总线技术-最新技术"
        )

        self.add_card(",
            "USB4 Version 2的特点是什么？",
            "总线技术-最新技术",
            "总线技术-最新技术"
        )

        self.add_card(",
            "CXL（Compute Express Link）的特点是什么？",
            "总线技术-最新技术",
            "总线技术-最新技术"
        )

        self.add_card(",
            "MIPI I3C的特点是什么？",
            "总线技术-最新技术",
            "总线技术-最新技术"
        )

        self.add_card(",
            "Chiplet（芯粒）总线的特点是什么？",
            "总线技术-最新技术",
            "总线技术-最新技术"
        )

        self.add_card(",
            "总线技术的核心挑战与未来方向是什么？",
            "总线技术-发展趋势",
            "总线技术-发展趋势"
        )

        self.add_card(",
            "不同场景下如何选择合适的总线？总线选型建议是什么？",
            "总线技术-选型建议",
            "总线技术-选型建议"
        )

        self.add_card(",
            "并行总线时代的特点和局限是什么？ISA、PCI、AGP的特点是什么？",
            "总线技术-基础理论",
            "总线技术-基础理论"
        )

    def generate_cpu_gpu_communication_cards(self):
        ""生成CPU/GPU通信相关的卡片""

        # 核心结论
        self.add_card(",
            "CPU与GPU通信的核心机制是什么？",
            "CPU/GPU通信-核心机制",
            "CPU/GPU通信-核心机制"
        )

        # 底层硬件基础
        self.add_card(",
            "CPU与GPU的核心互联总线有哪些？",
            "CPU/GPU通信-硬件基础",
            "CPU/GPU通信-硬件基础"
        )

        self.add_card(",
            "地址空间与IOMMU的作用是什么？",
            "CPU/GPU通信-硬件基础",
            "CPU/GPU通信-硬件基础"
        )

        self.add_card(",
            "DMA引擎的作用是什么？",
            "CPU/GPU通信-硬件基础",
            "CPU/GPU通信-硬件基础"
        )

        # 驱动与系统层
        self.add_card(",
            "CPU与GPU通信的初始化与枚举流程是什么？",
            "CPU/GPU通信-驱动协议",
            "CPU/GPU通信-驱动协议"
        )

        self.add_card(",
            "CPU与GPU通信的核心机制有哪些？",
            "CPU/GPU通信-驱动协议",
            "CPU/GPU通信-驱动协议"
        )

        self.add_card(",
            "有System Level Cache（SLC）和没有SLC时，CPU给GPU下发任务的流程有什么区别？",
            "System Level Cache（SLC）的存在与否会显著影响CPU给GPU下发任务的流程，主要体现在数据准备、传输路径和性能方面。\n\n1. 有SLC时的任务下发流程：\n   - 步骤1：CPU准备数据\n     * CPU在系统内存中准备任务数据（如渲染命令、纹理数据、顶点数据等）\n     * 数据写入系统内存时，如果数据在SLC的缓存范围内，会被自动缓存到SLC\n",
            "CPU/GPU通信-通信流程"

        # 完整通信流程示例
        self.add_card(
            "CUDA计算任务的完整通信流程是什么？",",
            "完整通信流程示例（以CUDA计算任务为例）：\n1. 环境准备：CPU驱动初始化GPU，分配系统内存和显存，建立SVM区域，创建命令队列\n2. 数据准备：方式1（显式搬运）- CPU将计算数据写入系统内存，驱动发起DMA请求，GPU DMA引擎将数据从系统内存搬运至显存；方式2（SVM）- CPU直接在SVM区域写入数据，GPU着色器通过虚拟地址直接访问，无需拷贝\n3. 任务提交：CPU将计算任务（如核函数参数、执行配置）封装为命令包，写入GPU的命令缓冲区；通过PCIe发送门铃（Doorbell）信号，触发GPU执行命令\n4. GPU执行：GPU硬件调度器取出命令，启动着色器核心执行计算任务；执行过程中，若需要访问系统内存，通过IOMMU转换地址，直接读取\n5. 结果回传：显式- GPU DMA引擎将计算结果从显存搬运至系统内存，完成后触发中断；SVM- GPU直接将结果写入SVM区域\n6. 同步与清理：CPU通过栅栏等待GPU任务完成，读取计算结果，释放内存和命令队列",
            "CPU/GPU通信-通信流程"
        )

        # 关键优化技术
        self.add_card(",
            "CPU与GPU通信的关键优化技术有哪些？",
            "CPU/GPU通信-优化技术",
            "CPU/GPU通信-优化技术"
        )

        self.add_card(",
            "共享虚拟内存（SVM）的优势是什么？",
            "CPU/GPU通信-优化技术",
            "CPU/GPU通信-优化技术"
        )

        # 常见通信瓶颈与解决方法
        self.add_card(",
            "CPU与GPU通信的常见瓶颈和解决方法是什么？",
            "CPU/GPU通信-瓶颈解决",
            "CPU/GPU通信-瓶颈解决"
        )

    def generate_android_graphics_cards(self):
        ""生成Android图形系统相关的卡片""

        self.add_card(",
            "Android应用内容上到屏幕的完整流程是什么？",
            "Android图形系统-完整流程",
            "Android图形系统-完整流程"
        )

        self.add_card(",
            "Surface在Android图形系统中的作用是什么？",
            "Android图形系统-Surface",
            "Android图形系统-Surface"
        )

        self.add_card(",
            "SurfaceFlinger的作用和工作原理是什么？",
            "Android图形系统-SurfaceFlinger",
            "Android图形系统-SurfaceFlinger"
        )

        self.add_card(",
            "HWC（Hardware Composer）的作用是什么？",
            "Android图形系统-HWC",
            "Android图形系统-HWC"
        )

        self.add_card(",
            "VSync（垂直同步）在Android图形系统中的作用是什么？",
            "Android图形系统-VSync",
            "Android图形系统-VSync"
        )

        self.add_card(",
            "Android图形系统中的硬件加速是什么？",
            "Android图形系统-硬件加速",
            "Android图形系统-硬件加速"
        )

        self.add_card(",
            "Display Controller（显示控制器）在硬件层面的作用是什么？",
            "Android图形系统-硬件",
            "Android图形系统-硬件"
        )

        self.add_card(",
            "DRM（Direct Rendering Manager）和KMS（Kernel Mode Setting）的作用是什么？",
            "Android图形系统-驱动",
            "Android图形系统-驱动"
        )

        self.add_card(",
            "MIPI DSI接口在显示流程中的作用是什么？",
            "Android图形系统-接口",
            "Android图形系统-接口"
        )

        self.add_card(",
            "Android图形系统中的双缓冲和三缓冲机制是什么？",
            "Android图形系统-缓冲机制",
            "Android图形系统-缓冲机制"
        )

    def generate_daemon_service_cards(self):
        ""生成守护进程和服务相关的卡片""

        self.add_card(",
            "守护进程（Daemon）和服务（Service）的区别是什么？",
            "守护进程/服务-基础",
            "守护进程/服务-基础"
        )

        self.add_card(",
            "如何创建一个守护进程？"/\")：改变到根目录\n   - 避免占用文件系统\n5. 重定向文件描述符：\n   - 关闭stdin、stdout、stderr\n   - 重定向到/dev/null\n6. 设置umask：\n   - umask(0)：清除文件创建掩码\n7. 处理信号：\n   - 忽略SIGHUP等信号\n   - 注册信号处理函数",",
            "守护进程/服务-创建"
        )

        self.add_card(
            "Android Native层daemon进程的特点是什么？",",
            "1. 生命周期：\n   - 由init进程启动（通过init.rc配置）\n   - 系统启动时自动启动\n   - 进程死亡后自动重启\n2. 权限：\n   - 运行在特定SELinux域\n   - 有特定的权限和capability\n3. 通信方式：\n   - Binder：与Java层和其他native进程通信\n   - Socket：本地socket通信\n   - 共享内存：高效的数据共享\n4. 资源限制：\n   - 内存增量限制（如ColorOS中的严格限制）\n   - CPU调度优先级\n5. 日志：\n   - 通过logcat输出日志\n   - 可以配置日志级别\n6. 应用场景：\n   - 系统服务（如SurfaceFlinger）\n   - 后台数据处理（如功耗大数据daemon）\n   - 硬件抽象层（HAL）",
            "守护进程/服务-Android"
        )

        self.add_card(",
            "systemd服务与传统的init服务有什么区别？",
            "守护进程/服务-systemd",
            "守护进程/服务-systemd"
        )

        self.add_card(",
            "Android中的服务（Service）有哪些类型？",
            "守护进程/服务-Android类型",
            "守护进程/服务-Android类型"
        )

        self.add_card(",
            "如何实现一个Android Native层daemon进程？",
            "守护进程/服务-实现",
            "守护进程/服务-实现"
        )

        self.add_card(",
            "守护进程如何与用户空间通信？",
            "守护进程/服务-通信",
            "守护进程/服务-通信"
        )

    def generate_session_process_group_cards(self):
        ""生成会话与进程组相关的卡片""

        self.add_card(",
            "什么是进程组（Process Group）？",
            "会话/进程组-进程组",
            "会话/进程组-进程组"
        )

        self.add_card(",
            "什么是会话（Session）？",
            "会话/进程组-会话",
            "会话/进程组-会话"
        )

        self.add_card(",
            "进程组和会话的关系是什么？",
            "会话/进程组-关系",
            "会话/进程组-关系"
        )

        self.add_card(",
            "什么是前台进程组和后台进程组？",
            "会话/进程组-前后台",
            "会话/进程组-前后台"
        )

        self.add_card(",
            "如何创建新会话？setsid()的作用是什么？",
            "会话/进程组-创建会话",
            "会话/进程组-创建会话"
        )

        self.add_card(",
            "如何向进程组发送信号？",
            "会话/进程组-信号",
            "会话/进程组-信号"
        )

        self.add_card(",
            "Shell中的作业控制是如何实现的？",
            "会话/进程组-作业控制",
            "会话/进程组-作业控制"
        )

        self.add_card(",
            "守护进程为什么要创建新会话？",
            "会话/进程组-守护进程",
            "会话/进程组-守护进程"
        )

        self.add_card(",
            "进程组和会话在Android系统中的应用？",
            "会话/进程组-Android",
            "会话/进程组-Android"
        )

    def generate_interview_qa_cards(self):
        ""生成高通面试问答相关的卡片""

        self.add_card(",
            "为什么转行到软件开发？",
            "面试-通用问题",
            "面试-通用问题"
        )

        self.add_card(",
            "端侧功耗大数据项目的跨度为什么比较大？",
            "面试-项目问题",
            "面试-项目问题"
        )

        self.add_card(",
            "功耗大数据对高通团队的价值是什么？",
            "面试-业务理解",
            "面试-业务理解"
        )

        self.add_card(",
            "如何从业务角度理解大数据的目的和作用？",
            "面试-业务理解",
            "面试-业务理解"
        )

    def generate_anki_csv(self, filename: str = "work_general_knowledge_anki.csv"):
        ""生成Anki格式的CSV文件""
        with open(filename, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)
            # Anki CSV格式：Front, Back, Tags
            for card in self.cards:
                # 将问题和答案格式化为HTML，设置左对齐样式
                question_html = self.format_text_for_anki(card['question'])
                answer_html = self.format_text_for_anki(card['answer'])
                writer.writerow([
                    question_html,
                    answer_html,
                    card['category']
                ])
        print(f"已生成Anki CSV文件：{filename}")
        print(f"共 {len(self.cards)} 张卡片")

    def generate_markdown(self, filename: str = "work_general_knowledge.md"):
        ""生成Markdown格式的卡片文件""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# 工作通识知识记忆卡片\n\n")
            f.write(f"共 {len(self.cards)} 张卡片\n\n")
            f.write("---\n\n")

            # 按分类组织
            categories = {}
            for card in self.cards:
                cat = card['category']
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(card)

            # 按主分类分组
            main_categories = {}
            for category, cards in categories.items():
                # 解析分类：主分类-子分类 或 主分类
                if '-' in category:
                    main_cat, sub_cat = category.split('-', 1)
                else:
                    main_cat = category
                    sub_cat = None

                if main_cat not in main_categories:
                    main_categories[main_cat] = {}
                if sub_cat:
                    main_categories[main_cat][sub_cat] = cards
                else:
                    main_categories[main_cat][''] = cards

            # 主分类排序顺序
            category_order = [
                '项目经历', 'SoC功耗', 'SoC架构', 'Trace工具',
                'PMIC/Gauge', 'Power Supply', 'Kernel调度',
                '操作系统基础', '总线技术', 'CPU/GPU通信',
                'Android图形系统', '守护进程/服务', '会话/进程组', '面试'
            ]

            # 按顺序输出
            for main_cat in category_order:
                if main_cat not in main_categories:
                    continue

                f.write(f"## {main_cat}\n\n")

                # 输出子分类
                for sub_cat in sorted(main_categories[main_cat].keys()):
                    cards = main_categories[main_cat][sub_cat]
                    if sub_cat:
                        f.write(f"### {sub_cat}\n\n")

                    for i, card in enumerate(cards, 1):
                        f.write(f"#### 卡片 {i}\n\n")
                        f.write(f"**问题**：{card['question']}\n\n")
                        f.write(f"**答案**：\n\n{card['answer']}\n\n")
                        f.write("---\n\n")

                f.write("\n")

            # 输出其他未在顺序中的分类
            for main_cat in sorted(main_categories.keys()):
                if main_cat in category_order:
                    continue

                f.write(f"## {main_cat}\n\n")
                for sub_cat in sorted(main_categories[main_cat].keys()):
                    cards = main_categories[main_cat][sub_cat]
                    if sub_cat:
                        f.write(f"### {sub_cat}\n\n")

                    for i, card in enumerate(cards, 1):
                        f.write(f"#### 卡片 {i}\n\n")
                        f.write(f"**问题**：{card['question']}\n\n")
                        f.write(f"**答案**：\n\n{card['answer']}\n\n")
                        f.write("---\n\n")

                f.write("\n")

        print(f"已生成Markdown文件：{filename}")
        print(f"共 {len(self.cards)} 张卡片")

    def generate_all(self):
        ""生成所有卡片""
        print("正在生成记忆卡片...")

        # 生成各类卡片
        self.generate_project_cards()
        self.generate_soc_power_cards()
        self.generate_soc_architecture_cards()
        self.generate_trace_cards()
        self.generate_pmic_gauge_cards()
        self.generate_kernel_scheduler_cards()
        self.generate_power_supply_cards()
        self.generate_os_basics_cards()  # 新增：操作系统基础
        self.generate_bus_technology_cards()  # 新增：总线技术
        self.generate_cpu_gpu_communication_cards()  # 新增：CPU/GPU通信
        self.generate_android_graphics_cards()  # 新增：Android图形系统
        self.generate_daemon_service_cards()
        self.generate_session_process_group_cards()
        self.generate_interview_qa_cards()

        # 生成各种格式的文件
        self.generate_anki_csv()
        self.generate_markdown()
        # JSON文件已移除，不再生成

        # 统计信息
        categories = {}
        for card in self.cards:
            cat = card['category']
            categories[cat] = categories.get(cat, 0) + 1

        print("\n卡片分类统计：")
        for cat, count in sorted(categories.items()):
            print(f"  {cat}: {count} 张")

        print(f"\n总计：{len(self.cards)} 张卡片")

if __name__ == "__main__":
    generator = WorkGeneralKnowledgeGenerator()
    generator.generate_all()

